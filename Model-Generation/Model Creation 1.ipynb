{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BFlZYHLP1AyZ"
      },
      "outputs": [],
      "source": [
        "combinedInputPath = \"/mnt/SPDrive/SPGenerations/\" #The path to the folder containing the tokenized and graded data. If individualInput is true, this will be ignored\n",
        "\n",
        "individualInput = False #If true, the program will use the individual input paths below. If false, it will use the combinedInputPath above\n",
        "pathToTokenizedData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Tokenizer\\\\\"\n",
        "pathToGradeData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Grader\\\\\"\n",
        "\n",
        "GradesTokensName = \"\" #Specifiy the versions (name) of the grade and token files to use. Leave blank to use the newest version\n",
        "\n",
        "modelOutputPath = \"/mnt/SPDrive/SPGenerations/Models/\" #The path to the folder for the model output.\n",
        "\n",
        "import os\n",
        "def homePath(path):\n",
        "    if path[0] == \"~\":\n",
        "        return os.path.join(os.path.expanduser(\"~\"), path.strip(\"~/\"))\n",
        "    else:\n",
        "        return path\n",
        "\n",
        "if not individualInput:\n",
        "    pathToTokenizedData = os.path.join(combinedInputPath, \"Tokens/\")\n",
        "    pathToGradeData = os.path.join(combinedInputPath, \"Grades/\")\n",
        "\n",
        "if GradesTokensName == \"\":\n",
        "    #Use newest folder for each\n",
        "\n",
        "    #Get the newest folder for the tokens\n",
        "    tokensFolders = os.listdir(pathToTokenizedData)\n",
        "    tokensFolders.sort()\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData , tokensFolders[-1])\n",
        "\n",
        "    #Get the newest folder for the grades\n",
        "    gradesFolders = os.listdir(pathToGradeData)\n",
        "    gradesFolders.sort()\n",
        "    pathToGradeData = os.path.join(pathToGradeData,  gradesFolders[-1])\n",
        "else:\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData, GradesTokensName)\n",
        "    pathToGradeData = os.path.join(pathToGradeData, GradesTokensName)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nLHjdZFH05pS",
        "outputId": "1016b38b-0f18-42e3-8e28-1e03019b46a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-13 06:01:03.325612: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-02-13 06:01:03.360939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-13 06:01:03.360965: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-13 06:01:03.360996: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-13 06:01:03.368211: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tokenCode  \\\n",
            "0       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "1       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "2       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "3       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "4       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "...                                                   ...   \n",
            "180568  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "180569  [44, 284, 28, 284, 28, 1, 28, 266, 44, 1, 28, ...   \n",
            "180570  [28, 682, 44, 284, 28, 284, 28, 1, 28, 266, 44...   \n",
            "180571  [44, 284, 28, 284, 28, 1, 28, 266, 44, 1, 28, ...   \n",
            "180572  [28, 682, 44, 284, 28, 284, 28, 1, 28, 266, 44...   \n",
            "\n",
            "                                                     Path  fileGrade  \n",
            "0       3722273/examples/basics/linear_regression.py/1.py  59.000000  \n",
            "1       3722273/examples/basics/linear_regression.py/2.py  66.000000  \n",
            "2       3722273/examples/basics/linear_regression.py/3.py  67.000000  \n",
            "3       3722273/examples/basics/linear_regression.py/0.py  55.000000  \n",
            "4       3722273/examples/basics/linear_regression.py/4.py  71.000000  \n",
            "...                                                   ...        ...  \n",
            "180568                       3912822/pelicanconf.py/18.py  61.792453  \n",
            "180569                      3912822/article_maker.py/1.py  56.666667  \n",
            "180570                     3912822/article_maker.py/11.py  73.333333  \n",
            "180571                      3912822/article_maker.py/2.py  58.333333  \n",
            "180572                      3912822/article_maker.py/6.py  65.000000  \n",
            "\n",
            "[180573 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU, Dropout, Bidirectional, Input, Flatten, Concatenate\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "import keras.layers as layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "#Load the data\n",
        "#tokenized data is in tokenizedData.pkl, has tokenizer obj in tokenizer.json\n",
        "\n",
        "#Load the tokenizer\n",
        "with open(pathToTokenizedData+ \"/tokenizer.json\", \"r\") as f:\n",
        "    tokenizer = tokenizer_from_json(f.read())\n",
        "\n",
        "\n",
        "\n",
        "#Load the tokenized data\n",
        "with open(pathToTokenizedData + \"/tokenizedData.pkl\", \"rb\") as f:\n",
        "    tokenizedData = pickle.load(f)\n",
        "\n",
        "#Load the grade data\n",
        "#gradeData is a dict with keys as the file names and values as the grades\n",
        "with open(pathToGradeData + \"/grades.pkl\", \"rb\") as f:\n",
        "    gradeData = pickle.load(f)\n",
        "\n",
        "#load the group data\n",
        "#with open(pathToTokenizedData + \"/tokenGroupDataframe.pkl\", \"rb\") as f:\n",
        "#    tokenizedGroupData = pickle.load(f)\n",
        "\n",
        "combinedDF = pd.merge(tokenizedData, gradeData, on = \"Path\")\n",
        "#combinedDF = pd.merge(combinedDF, tokenizedGroupData, on = \"Path\")\n",
        "print (combinedDF)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "rungraph = False\n",
        "if rungraph:\n",
        "    #chart of token length vs grade\n",
        "    tokenLengths = combinedDF[\"tokenCode\"].apply(lambda x: len(x))\n",
        "    plt.scatter(tokenLengths, combinedDF[\"fileGrade\"])\n",
        "    plt.xlabel(\"Token Length\")\n",
        "    plt.ylabel(\"Grade\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    #graph the density of the grades vs length\n",
        "    count = []\n",
        "    countLow = []\n",
        "    countHigh = []\n",
        "    for i in range(1, combinedDF[\"tokenCode\"].apply(lambda x: len(x)).max() + 1):\n",
        "        count.append(combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) == i][\"fileGrade\"].mean())\n",
        "        countLow.append(combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) == i][\"fileGrade\"].quantile(.25))\n",
        "        countHigh.append(combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) == i][\"fileGrade\"].quantile(.75))\n",
        "\n",
        "                    \n",
        "\n",
        "    plt.scatter(range(1, combinedDF[\"tokenCode\"].apply(lambda x: len(x)).max() + 1), count)\n",
        "    #draw a line of best fit\n",
        "    z = np.polyfit(range(1, combinedDF[\"tokenCode\"].apply(lambda x: len(x)).max() + 1), count, 1)\n",
        "    p = np.poly1d(z)\n",
        "    plt.xlabel(\"Token Length\")\n",
        "    plt.ylabel(\"Grade\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jnja4-p705pU",
        "outputId": "b79f4a7d-57af-4836-e052-f2089eaec5b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tokenCode  \\\n",
            "0       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "1       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "2       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "3       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "4       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "...                                                   ...   \n",
            "180559  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "180561  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "180564  [44, 422, 28, 1, 28, 266, 28, 79, 4, 24, 10, 3...   \n",
            "180565  [44, 422, 28, 1, 4, 24, 10, 3, 9, 3, 4, 25, 10...   \n",
            "180568  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "\n",
            "                                                     Path  fileGrade  \n",
            "0       3722273/examples/basics/linear_regression.py/1.py  59.000000  \n",
            "1       3722273/examples/basics/linear_regression.py/2.py  66.000000  \n",
            "2       3722273/examples/basics/linear_regression.py/3.py  67.000000  \n",
            "3       3722273/examples/basics/linear_regression.py/0.py  55.000000  \n",
            "4       3722273/examples/basics/linear_regression.py/4.py  71.000000  \n",
            "...                                                   ...        ...  \n",
            "180559                       3912822/pelicanconf.py/20.py  62.547170  \n",
            "180561                       3912822/pelicanconf.py/28.py  65.566038  \n",
            "180564                       3912822/pelicanconf.py/33.py  67.452830  \n",
            "180565                        3912822/pelicanconf.py/0.py  55.000000  \n",
            "180568                       3912822/pelicanconf.py/18.py  61.792453  \n",
            "\n",
            "[31747 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#Padding\n",
        "\n",
        "maxLen = 500\n",
        "minLen = 100\n",
        "#get rid of the ones that are too long\n",
        "combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) <= maxLen]\n",
        "\n",
        "#shorten the ones that are too long\n",
        "#combinedDF[\"tokenCode\"] = combinedDF[\"tokenCode\"].apply(lambda x: x[:maxLen])\n",
        "#combinedDF = combinedDF[combinedDF[\"tokenGroupCode\"].apply(lambda x: len(x)) <= maxLen]\n",
        " \n",
        "\n",
        "#get rid of the ones that are too short\n",
        "combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) > minLen]\n",
        "#combinedDF = combinedDF[combinedDF[\"tokenGroupCode\"].apply(lambda x: len(x)) > minLen]\n",
        "\n",
        "#Pad the sequences\n",
        "combinedDF[\"tokenCode\"] = pad_sequences(combinedDF[\"tokenCode\"], maxlen = maxLen, padding = \"post\", truncating = \"post\").tolist()\n",
        "#combinedDF[\"tokenGroupCode\"] = pad_sequences(combinedDF[\"tokenGroupCode\"], maxlen = maxLen, padding = \"post\", truncating = \"post\").tolist()\n",
        "\n",
        "print (combinedDF)\n",
        "\n",
        "#only use 5% of the dat\n",
        "#combinedDF = combinedDF.sample(frac = 0.001, random_state = 1)\n",
        "\n",
        "#48590 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2-_lF4pW05pU",
        "outputId": "0568f4dd-be12-4884-c67e-9e8592184df6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#create a chart of the grades\n",
        "graph = plt.hist(combinedDF['fileGrade'], bins=20, range=(0, 100))\n",
        "plt.xticks([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100])\n",
        "plt.xlabel(\"Grade Range\")\n",
        "plt.ylabel(\"Number of Commits\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Nu6hyuey05pU",
        "outputId": "2d9cf582-6a4a-46ad-e21c-e84a8f2eecce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-13 06:01:22.453011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13173 MB memory:  -> device: 0, name: NVIDIA A2, pci bus id: 0000:11:00.0, compute capability: 8.6\n",
            "2024-02-13 06:01:22.454008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13173 MB memory:  -> device: 1, name: NVIDIA A2, pci bus id: 0000:b1:00.0, compute capability: 8.6\n",
            "2024-02-13 06:01:23.573739: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 500, 2048)         1638400   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 498, 2048)         12584960  \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 2048)              0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 2048)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 1, 2048)           25174016  \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 2048)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 1024)              10489856  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              4198400   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048)              8390656   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62478337 (238.34 MB)\n",
            "Trainable params: 62478337 (238.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-13 06:01:33.595186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2024-02-13 06:01:34.262950: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2024-02-13 06:01:39.787818: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83642e3310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-02-13 06:01:39.787840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A2, Compute Capability 8.6\n",
            "2024-02-13 06:01:39.787843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A2, Compute Capability 8.6\n",
            "2024-02-13 06:01:39.791718: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-02-13 06:01:39.899353: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "993/993 [==============================] - 258s 237ms/step - loss: 0.3234 - mse: 409.2336 - mae: 15.4743 - mape: 246218592.0000 - accuracy: 1.5750e-04\n",
            "Epoch 2/100\n",
            "993/993 [==============================] - 234s 236ms/step - loss: 0.1790 - mse: 235.0692 - mae: 11.9973 - mape: 79720944.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1741 - mse: 228.0331 - mae: 11.7261 - mape: 79631064.0000 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1584 - mse: 210.0208 - mae: 11.2040 - mape: 61262268.0000 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1572 - mse: 207.4631 - mae: 11.1418 - mape: 56081224.0000 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1468 - mse: 199.2506 - mae: 10.8402 - mape: 47524572.0000 - accuracy: 3.1499e-05\n",
            "Epoch 7/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1414 - mse: 192.6048 - mae: 10.6765 - mape: 42533664.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1385 - mse: 187.6084 - mae: 10.5038 - mape: 38939960.0000 - accuracy: 6.2998e-05\n",
            "Epoch 9/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1325 - mse: 182.5323 - mae: 10.3595 - mape: 37259532.0000 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1281 - mse: 181.2285 - mae: 10.3308 - mape: 30922748.0000 - accuracy: 2.5199e-04\n",
            "Epoch 11/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1296 - mse: 177.1483 - mae: 10.1781 - mape: 35152804.0000 - accuracy: 2.2049e-04\n",
            "Epoch 12/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1280 - mse: 176.7491 - mae: 10.1507 - mape: 34617132.0000 - accuracy: 3.1499e-05\n",
            "Epoch 13/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1244 - mse: 172.3054 - mae: 9.9939 - mape: 32765924.0000 - accuracy: 2.2049e-04\n",
            "Epoch 14/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1272 - mse: 174.9003 - mae: 10.1115 - mape: 33218400.0000 - accuracy: 1.2600e-04\n",
            "Epoch 15/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1197 - mse: 165.3431 - mae: 9.7764 - mape: 30669020.0000 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1188 - mse: 166.0453 - mae: 9.8371 - mape: 30588084.0000 - accuracy: 1.8899e-04\n",
            "Epoch 17/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1168 - mse: 162.7987 - mae: 9.6980 - mape: 28621172.0000 - accuracy: 9.4497e-05\n",
            "Epoch 18/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1198 - mse: 163.5206 - mae: 9.7182 - mape: 29577322.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1220 - mse: 166.3960 - mae: 9.7743 - mape: 29183184.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1174 - mse: 161.8596 - mae: 9.6741 - mape: 28438874.0000 - accuracy: 6.2998e-05\n",
            "Epoch 21/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1145 - mse: 156.4567 - mae: 9.4732 - mape: 28466532.0000 - accuracy: 3.1499e-05\n",
            "Epoch 22/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1110 - mse: 152.9827 - mae: 9.3741 - mape: 25850588.0000 - accuracy: 1.8899e-04\n",
            "Epoch 23/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1138 - mse: 155.7341 - mae: 9.4368 - mape: 28077266.0000 - accuracy: 2.2049e-04\n",
            "Epoch 24/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1119 - mse: 154.6208 - mae: 9.4084 - mape: 27308550.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1145 - mse: 156.3086 - mae: 9.4777 - mape: 27807320.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1083 - mse: 146.9668 - mae: 9.1597 - mape: 27061044.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1107 - mse: 152.7925 - mae: 9.3822 - mape: 27118400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1096 - mse: 155.9720 - mae: 9.4550 - mape: 26804526.0000 - accuracy: 1.2600e-04\n",
            "Epoch 29/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1077 - mse: 149.3645 - mae: 9.2426 - mape: 27003996.0000 - accuracy: 3.1499e-05\n",
            "Epoch 30/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1067 - mse: 147.8817 - mae: 9.2093 - mape: 26734298.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1064 - mse: 149.4126 - mae: 9.2600 - mape: 23993494.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1071 - mse: 151.1592 - mae: 9.3166 - mape: 25541132.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1119 - mse: 152.8457 - mae: 9.3659 - mape: 27698584.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1106 - mse: 154.8557 - mae: 9.4296 - mape: 26171064.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1113 - mse: 156.7878 - mae: 9.5044 - mape: 27103032.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1067 - mse: 149.6797 - mae: 9.2638 - mape: 24445812.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1099 - mse: 150.8314 - mae: 9.3133 - mape: 24715824.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1091 - mse: 150.3322 - mae: 9.2993 - mape: 27110484.0000 - accuracy: 6.2998e-05\n",
            "Epoch 39/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1035 - mse: 145.1147 - mae: 9.0644 - mape: 24656144.0000 - accuracy: 6.2998e-05\n",
            "Epoch 40/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1064 - mse: 150.8679 - mae: 9.3336 - mape: 23381804.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1097 - mse: 151.8926 - mae: 9.3429 - mape: 26745324.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1072 - mse: 152.2795 - mae: 9.3514 - mape: 24777696.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1036 - mse: 145.9185 - mae: 9.1343 - mape: 24733320.0000 - accuracy: 3.1499e-04\n",
            "Epoch 44/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1066 - mse: 147.6967 - mae: 9.2056 - mape: 25255828.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1066 - mse: 146.2042 - mae: 9.1245 - mape: 26330808.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1030 - mse: 145.4614 - mae: 9.0913 - mape: 24086308.0000 - accuracy: 3.1499e-05\n",
            "Epoch 47/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1065 - mse: 148.9029 - mae: 9.2492 - mape: 23769300.0000 - accuracy: 6.6148e-04\n",
            "Epoch 48/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1043 - mse: 143.3202 - mae: 9.0660 - mape: 25883226.0000 - accuracy: 3.1499e-05\n",
            "Epoch 49/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1063 - mse: 144.7864 - mae: 9.1254 - mape: 26591286.0000 - accuracy: 4.0949e-04\n",
            "Epoch 50/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1092 - mse: 148.9525 - mae: 9.2652 - mape: 28995354.0000 - accuracy: 0.0011\n",
            "Epoch 51/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1063 - mse: 147.5064 - mae: 9.2028 - mape: 27625572.0000 - accuracy: 1.5750e-04\n",
            "Epoch 52/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1126 - mse: 150.3838 - mae: 9.2971 - mape: 30441652.0000 - accuracy: 2.2049e-04\n",
            "Epoch 53/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1053 - mse: 141.6711 - mae: 8.9741 - mape: 28496750.0000 - accuracy: 6.2998e-05\n",
            "Epoch 54/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1054 - mse: 139.5502 - mae: 8.9083 - mape: 29226414.0000 - accuracy: 6.2998e-05\n",
            "Epoch 55/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1042 - mse: 139.4803 - mae: 8.9072 - mape: 25955616.0000 - accuracy: 6.2998e-05\n",
            "Epoch 56/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1050 - mse: 143.0040 - mae: 9.0323 - mape: 26275324.0000 - accuracy: 5.9848e-04\n",
            "Epoch 57/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1050 - mse: 146.8162 - mae: 9.1405 - mape: 26857498.0000 - accuracy: 3.7799e-04\n",
            "Epoch 58/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1030 - mse: 143.6983 - mae: 9.0631 - mape: 23659800.0000 - accuracy: 3.1499e-05\n",
            "Epoch 59/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1026 - mse: 141.0504 - mae: 8.9550 - mape: 24134794.0000 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1046 - mse: 143.0382 - mae: 9.0201 - mape: 27621248.0000 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1055 - mse: 146.5903 - mae: 9.1802 - mape: 24525106.0000 - accuracy: 3.1499e-05\n",
            "Epoch 62/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1052 - mse: 146.7796 - mae: 9.1912 - mape: 25708988.0000 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1010 - mse: 143.0836 - mae: 9.0412 - mape: 23817768.0000 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1044 - mse: 143.8228 - mae: 9.0581 - mape: 23355830.0000 - accuracy: 9.4497e-05\n",
            "Epoch 65/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1057 - mse: 145.3629 - mae: 9.1139 - mape: 26992868.0000 - accuracy: 6.2998e-04\n",
            "Epoch 66/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1065 - mse: 148.8797 - mae: 9.2046 - mape: 28759984.0000 - accuracy: 5.3548e-04\n",
            "Epoch 67/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1050 - mse: 145.8507 - mae: 9.1167 - mape: 25839336.0000 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.1007 - mse: 139.7858 - mae: 8.9253 - mape: 23513258.0000 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1024 - mse: 141.8733 - mae: 9.0182 - mape: 25939498.0000 - accuracy: 9.4497e-05\n",
            "Epoch 70/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1096 - mse: 145.6182 - mae: 9.1516 - mape: 30287272.0000 - accuracy: 9.1347e-04\n",
            "Epoch 71/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1020 - mse: 139.8424 - mae: 8.9234 - mape: 25787704.0000 - accuracy: 4.0949e-04\n",
            "Epoch 72/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0994 - mse: 137.0030 - mae: 8.8429 - mape: 24528928.0000 - accuracy: 5.6698e-04\n",
            "Epoch 73/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1019 - mse: 139.0107 - mae: 8.8851 - mape: 27870564.0000 - accuracy: 3.1499e-05\n",
            "Epoch 74/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1046 - mse: 140.8697 - mae: 8.9772 - mape: 26385764.0000 - accuracy: 3.1499e-05\n",
            "Epoch 75/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1084 - mse: 149.1970 - mae: 9.2385 - mape: 26740972.0000 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1094 - mse: 148.7969 - mae: 9.2072 - mape: 28809336.0000 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1054 - mse: 143.2641 - mae: 9.0294 - mape: 28920484.0000 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1077 - mse: 147.8586 - mae: 9.2178 - mape: 28845784.0000 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1067 - mse: 147.5092 - mae: 9.1890 - mape: 26804840.0000 - accuracy: 6.2998e-05\n",
            "Epoch 80/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1086 - mse: 149.3638 - mae: 9.2585 - mape: 26125054.0000 - accuracy: 3.1499e-04\n",
            "Epoch 81/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1067 - mse: 146.2176 - mae: 9.1218 - mape: 28350704.0000 - accuracy: 3.1499e-05\n",
            "Epoch 82/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1061 - mse: 145.6285 - mae: 9.1489 - mape: 27075050.0000 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1058 - mse: 143.6847 - mae: 9.0408 - mape: 28033780.0000 - accuracy: 9.4497e-04\n",
            "Epoch 84/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1031 - mse: 142.0191 - mae: 9.0245 - mape: 26516438.0000 - accuracy: 5.3548e-04\n",
            "Epoch 85/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1081 - mse: 149.3001 - mae: 9.2675 - mape: 26108960.0000 - accuracy: 3.1499e-04\n",
            "Epoch 86/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1076 - mse: 148.2700 - mae: 9.2671 - mape: 23606966.0000 - accuracy: 8.1898e-04\n",
            "Epoch 87/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1093 - mse: 150.1083 - mae: 9.2749 - mape: 25456256.0000 - accuracy: 9.1347e-04\n",
            "Epoch 88/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1096 - mse: 158.3114 - mae: 9.5597 - mape: 24457448.0000 - accuracy: 6.2998e-05\n",
            "Epoch 89/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1057 - mse: 152.5626 - mae: 9.3959 - mape: 23271592.0000 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1033 - mse: 143.5571 - mae: 9.0855 - mape: 24005604.0000 - accuracy: 6.2998e-05\n",
            "Epoch 91/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.1004 - mse: 140.7890 - mae: 8.9979 - mape: 24529806.0000 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0994 - mse: 137.2514 - mae: 8.7977 - mape: 24390986.0000 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0988 - mse: 137.5407 - mae: 8.8276 - mape: 24866210.0000 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0998 - mse: 137.7656 - mae: 8.8252 - mape: 23878422.0000 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0985 - mse: 136.7297 - mae: 8.7988 - mape: 22651544.0000 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0964 - mse: 134.2963 - mae: 8.7451 - mape: 21481548.0000 - accuracy: 6.2998e-05\n",
            "Epoch 97/100\n",
            "993/993 [==============================] - 235s 237ms/step - loss: 0.0959 - mse: 133.0974 - mae: 8.6913 - mape: 23293908.0000 - accuracy: 1.2600e-04\n",
            "Epoch 98/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0971 - mse: 135.0406 - mae: 8.7455 - mape: 23783142.0000 - accuracy: 6.2998e-04\n",
            "Epoch 99/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0977 - mse: 137.9764 - mae: 8.8447 - mape: 22666092.0000 - accuracy: 3.1499e-05\n",
            "Epoch 100/100\n",
            "993/993 [==============================] - 235s 236ms/step - loss: 0.0980 - mse: 139.3157 - mae: 8.9057 - mape: 22983146.0000 - accuracy: 3.1499e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mcall/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/TokenizerManager.py\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/CaMlSupportingClasses.py\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/PythonProcessing.py\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/__pycache__/\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/__pycache__/CaMlSupportingClasses.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/__pycache__/CodeSimilarization.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/__pycache__/PythonProcessing.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/__pycache__/TokenProcessing.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/TokenProcessing.py\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/SupportingClasses/CodeSimilarization.py\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/__pycache__/\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/__pycache__/CaMlSupportingClasses.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/__pycache__/TokenizerManager.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/__pycache__/CLPTokenizer.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/.gitignore\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/Definitions.md\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/.git\n",
            "/home/mcall/SPGit/Model-Generation/SCA-Tokenizer/README.md\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/Grader.py\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/SupportingClasses/\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/SupportingClasses/CaMlSupportingClasses.py\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/SupportingClasses/__pycache__/\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/SupportingClasses/__pycache__/CaMlSupportingClasses.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/__pycache__/\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/__pycache__/Grader.cpython-310.pyc\n",
            "/home/mcall/SPGit/Model-Generation/../Auto-Grader/Readme.md\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "tar: Removing leading `/home/mcall/SPGit/Model-Generation/../' from member names\n"
          ]
        }
      ],
      "source": [
        "#if (not gpu_detected):\n",
        "#    print(\"GPU not detected, using CPU\")\n",
        "\n",
        "\n",
        "#Create the model\n",
        "#Input\n",
        "inputTokens = layers.Input(shape=(maxLen,), dtype='int32')\n",
        "\n",
        "#Embedding\n",
        "embedding = layers.Embedding(tokenizer.num_words, 2048, input_length=maxLen)(inputTokens)\n",
        "\n",
        "#Convolutional\n",
        "convolutional = layers.Conv1D(2048, 3, activation='relu')(embedding)\n",
        "convolutional = layers.GlobalMaxPooling1D()(convolutional)\n",
        "convolutional = layers.Reshape((1, 2048))(convolutional)\n",
        "\n",
        "#LSTM\n",
        "lstm = layers.Bidirectional(LSTM(1024, return_sequences=True))(convolutional)\n",
        "lstm = Dropout(0.38479930887149405)(lstm)\n",
        "lstm = layers.Bidirectional(LSTM(512))(lstm)\n",
        "\n",
        "#Dense\n",
        "dense = layers.Flatten()(lstm)\n",
        "dense = layers.Dense(4096, activation='relu')(dense)\n",
        "dense = layers.Dense(2048, activation='relu')(dense)\n",
        "dense = layers.Dense(1, activation='relu')(dense)\n",
        "\n",
        "#Output\n",
        "output = dense\n",
        "\n",
        "\n",
        "model = Model(inputs=inputTokens, outputs=output)\n",
        "\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['mse', 'mae', 'mape', 'accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# convert inputs to numpy arrays\n",
        "token_code = np.array(combinedDF[\"tokenCode\"].tolist())\n",
        "file_grade = np.array(combinedDF[\"fileGrade\"].tolist())\n",
        "#convert file_grade to floats from strings\n",
        "file_grade = np.array(list(map(float, file_grade)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hist = model.fit(token_code, file_grade, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "\n",
        "#Save the model in timestamp folder and with tokenizer\n",
        "timestamp = str(pd.Timestamp.now()).replace(\" \", \"_\").replace(\":\", \"-\").replace(\".\", \"-\")\n",
        "if not os.path.exists(modelOutputPath):\n",
        "    os.mkdir(modelOutputPath)\n",
        "if not os.path.exists(modelOutputPath + \"/\" + timestamp):\n",
        "    os.mkdir(modelOutputPath + \"/\" + timestamp)\n",
        "model.save(modelOutputPath + \"/\" + timestamp + \"/model.h5\")\n",
        "with open(modelOutputPath + \"/\" + timestamp + \"/tokenizer.json\", \"w\") as f:\n",
        "    f.write(tokenizer.to_json())\n",
        "#make an archaive of the SCA-Tokenizer Folder\n",
        "#get CWD\n",
        "cwd = os.getcwd()\n",
        "if os.path.exists(os.path.join(cwd, \"SCA-Tokenizer\")):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/SCA-Tokenizer.tar.gz\\\" \" + os.path.join(cwd, \"SCA-Tokenizer\"))\n",
        "\n",
        "#Save the AutoGrader Folder\n",
        "autoGraderDir = os.path.join(cwd, \"../Auto-Grader/\")\n",
        "if os.path.exists(autoGraderDir):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/Auto-Grader.tar.gz\\\" \" + autoGraderDir)\n",
        "\n",
        "#Save tokenizedGroupData\n",
        "#copy GroupDict.npy from the tokenizer folder to the model folder\n",
        "if os.path.exists(os.path.join(cwd, \"SCA-Tokenizer\", \"GroupDict.npy\")):\n",
        "    os.system(\"cp \" + os.path.join(cwd, \"SCA-Tokenizer\", \"GroupDict.npy\") + \" \" + os.path.join(modelOutputPath, timestamp, \"GroupDict.npy\"))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
