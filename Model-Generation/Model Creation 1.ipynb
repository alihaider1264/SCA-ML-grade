{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BFlZYHLP1AyZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def homePath(path):\n",
        "    if path[0] == \"~\":\n",
        "        return os.path.join(os.path.expanduser(\"~\"), path.strip(\"~/\"))\n",
        "    else:\n",
        "        return path\n",
        "\n",
        "#Model Creation 1\n",
        "#Figure out how to do versioning effectively\n",
        "individualInput = False\n",
        "combinedInputPath = \"/home/jaredrussell/CPPMLGen\"\n",
        "#combinedInputPath = \"/home/jaredrussell/CPPMLGenMini\"\n",
        "pathToTokenizedData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Tokenizer\\\\\"\n",
        "pathToGradeData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Grader\\\\\"\n",
        "GradesTokensName = \"\"\n",
        "\n",
        "\n",
        "if not individualInput:\n",
        "    pathToTokenizedData = os.path.join(combinedInputPath, \"Tokens/\")\n",
        "    pathToGradeData = os.path.join(combinedInputPath, \"Grades/\")\n",
        "\n",
        "if GradesTokensName == \"\":\n",
        "    #Use newest folder for each\n",
        "\n",
        "    #Get the newest folder for the tokens\n",
        "    tokensFolders = os.listdir(pathToTokenizedData)\n",
        "    tokensFolders.sort()\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData , tokensFolders[-1])\n",
        "\n",
        "    #Get the newest folder for the grades\n",
        "    gradesFolders = os.listdir(pathToGradeData)\n",
        "    gradesFolders.sort()\n",
        "    pathToGradeData = os.path.join(pathToGradeData,  gradesFolders[-1])\n",
        "else:\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData, GradesTokensName)\n",
        "    pathToGradeData = os.path.join(pathToGradeData, GradesTokensName)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "modelOutputPath = \"/home/jaredrussell/CPPMLGen/Models\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nLHjdZFH05pS",
        "outputId": "1016b38b-0f18-42e3-8e28-1e03019b46a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-29 16:14:33.742402: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-29 16:14:33.775775: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 16:14:33.775802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 16:14:33.776718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 16:14:33.782191: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-29 16:14:33.782743: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-29 16:14:34.452957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tokenCode  \\\n",
            "1        8 8 8 8 280 2 489 1 8 280 2 489 1 8 8 138 405...   \n",
            "4        8 8 8 8 280 2 489 1 8 280 2 489 1 8 8 138 405...   \n",
            "27       165 12 12 12 280 2 118 1 2 1 12 280 2 118 1 2...   \n",
            "28       28 28 28 28 28 28 28 28 28 156 18 2 11 42 1 5...   \n",
            "29       165 12 12 12 280 2 118 1 2 1 12 280 2 118 1 2...   \n",
            "...                                                   ...   \n",
            "117158   45 19 718 280 2 489 1 138 30 359 496 3 302 15...   \n",
            "117159   45 19 718 280 2 489 1 41 138 30 359 496 3 302...   \n",
            "117161   45 19 718 280 2 489 1 41 138 30 359 496 3 302...   \n",
            "117163   28 8 15 8 358 149 192 51 306 8 50 3 28 28 2 1...   \n",
            "117170   28 28 45 2 1 261 209 150 405 47 83 97 526 86 ...   \n",
            "\n",
            "                                                     Path  \n",
            "1                                3385567/RBHook.cpp/0.cpp  \n",
            "4                                3385567/RBHook.cpp/1.cpp  \n",
            "27         3265841/app/src/main/cpp/passman-lib.cpp/4.cpp  \n",
            "28         3265841/app/src/main/cpp/passman-lib.cpp/0.cpp  \n",
            "29         3265841/app/src/main/cpp/passman-lib.cpp/7.cpp  \n",
            "...                                                   ...  \n",
            "117158  3397270/examples/80.Modules/02.CharlieplexTiny...  \n",
            "117159  3397270/examples/80.Modules/02.CharlieplexTiny...  \n",
            "117161  3397270/examples/80.Modules/02.CharlieplexTiny...  \n",
            "117163  3397270/examples/80.Modules/02.CharlieplexTiny...  \n",
            "117170  3397270/examples/90.Tools/02.Tiny_UniProg/Fuse...  \n",
            "\n",
            "[48842 rows x 2 columns]\n",
            "        fileGrade                                               Path\n",
            "0       55.000000                           3385567/RBHook.cpp/0.cpp\n",
            "1       64.333333                           3385567/RBHook.cpp/1.cpp\n",
            "2       67.666667                           3385567/RBHook.cpp/2.cpp\n",
            "3       65.000000                           3385567/RBHook.cpp/3.cpp\n",
            "4       68.333333                           3385567/RBHook.cpp/4.cpp\n",
            "...           ...                                                ...\n",
            "154153  39.133333  3397270/examples/90.Tools/02.Tiny_UniProg/LEDs...\n",
            "154154  19.800000  3397270/examples/90.Tools/02.Tiny_UniProg/ATTi...\n",
            "154155  26.466667  3397270/examples/90.Tools/02.Tiny_UniProg/ATTi...\n",
            "154156  39.133333  3397270/examples/90.Tools/02.Tiny_UniProg/ATTi...\n",
            "154157  19.800000  3397270/examples/90.Tools/02.Tiny_UniProg/Fuse...\n",
            "\n",
            "[154158 rows x 2 columns]\n",
            "                                               tokenCode  \\\n",
            "0       8 8 8 8 280 2 489 1 8 280 2 489 1 8 8 138 405...   \n",
            "1       8 8 8 8 280 2 489 1 8 280 2 489 1 8 8 138 405...   \n",
            "2       165 12 12 12 280 2 118 1 2 1 12 280 2 118 1 2...   \n",
            "3       28 28 28 28 28 28 28 28 28 156 18 2 11 42 1 5...   \n",
            "4       165 12 12 12 280 2 118 1 2 1 12 280 2 118 1 2...   \n",
            "...                                                  ...   \n",
            "48432   45 19 718 280 2 489 1 138 30 359 496 3 302 15...   \n",
            "48433   45 19 718 280 2 489 1 41 138 30 359 496 3 302...   \n",
            "48434   45 19 718 280 2 489 1 41 138 30 359 496 3 302...   \n",
            "48435   28 8 15 8 358 149 192 51 306 8 50 3 28 28 2 1...   \n",
            "48436   28 28 45 2 1 261 209 150 405 47 83 97 526 86 ...   \n",
            "\n",
            "                                                    Path  fileGrade  \n",
            "0                               3385567/RBHook.cpp/0.cpp  55.000000  \n",
            "1                               3385567/RBHook.cpp/1.cpp  64.333333  \n",
            "2         3265841/app/src/main/cpp/passman-lib.cpp/4.cpp  64.288889  \n",
            "3         3265841/app/src/main/cpp/passman-lib.cpp/0.cpp  40.400000  \n",
            "4         3265841/app/src/main/cpp/passman-lib.cpp/7.cpp  70.955556  \n",
            "...                                                  ...        ...  \n",
            "48432  3397270/examples/80.Modules/02.CharlieplexTiny...  19.800000  \n",
            "48433  3397270/examples/80.Modules/02.CharlieplexTiny...  40.800000  \n",
            "48434  3397270/examples/80.Modules/02.CharlieplexTiny...  35.800000  \n",
            "48435  3397270/examples/80.Modules/02.CharlieplexTiny...  19.800000  \n",
            "48436  3397270/examples/90.Tools/02.Tiny_UniProg/Fuse...  19.800000  \n",
            "\n",
            "[48437 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "import keras.layers as layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append('./SCA-Tokenizer/')\n",
        "import CLPTokenizer as CLPTokenizer\n",
        "\n",
        "\n",
        "\n",
        "#Load the data\n",
        "#tokenized data is in tokenizedData.pkl, has tokenizer obj in tokenizer.json\n",
        "\n",
        "#Load the tokenizer\n",
        "with open(pathToTokenizedData + \"/tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f, encoding='latin1')\n",
        "\n",
        "\n",
        "#Load the tokenized data\n",
        "with open(pathToTokenizedData + \"/tokenizedData.pkl\", \"rb\") as f:\n",
        "    tokenizedData = pickle.load(f)\n",
        "\n",
        "print (tokenizedData)\n",
        "\n",
        "#Load the grade data\n",
        "#gradeData is a dict with keys as the file names and values as the grades\n",
        "with open(pathToGradeData + \"/grades.pkl\", \"rb\") as f:\n",
        "    gradeData = pickle.load(f)\n",
        "\n",
        "print (gradeData)\n",
        "\n",
        "#load the group data\n",
        "#with open(pathToTokenizedData + \"/tokenGroupDataframe.pkl\", \"rb\") as f:\n",
        "#    tokenizedGroupData = pickle.load(f)\n",
        "\n",
        "combinedDF = pd.merge(tokenizedData, gradeData, on = \"Path\")\n",
        "#combinedDF = pd.merge(combinedDF, tokenizedGroupData, on = \"Path\")\n",
        "print (combinedDF)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jnja4-p705pU",
        "outputId": "b79f4a7d-57af-4836-e052-f2089eaec5b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: ' 28 28 28 28 28 28 28 28 28 156 18 2 11 42 1 5 8 775 159 538 386 118 4 2 1 3 7 2 52 17 118 1 5 605 358 118 4 2 1 3 6 2 118 315 1 3 6 123 142 5 2 212 1 5 55 4 2 9 1 3 55 4 2 212 9 1 3 4 2 2 11 40 42 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model Creation 1.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m combinedDF \u001b[39m=\u001b[39m combinedDF[combinedDF[\u001b[39m\"\u001b[39m\u001b[39mtokenCode\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x)) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m maxLen \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#shorten the ones that are too long FOR TESTING\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#combinedDF[\"tokenCode\"] = combinedDF[\"tokenCode\"].tolist.apply(lambda x: [int(i) for i in x.split()[:maxLen]])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#Pad the sequences\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m combinedDF[\u001b[39m\"\u001b[39m\u001b[39mtokenCode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pad_sequences(combinedDF[\u001b[39m\"\u001b[39;49m\u001b[39mtokenCode\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), maxlen \u001b[39m=\u001b[39;49m maxLen, padding \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, truncating \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#combinedDF[\"tokenGroupCode\"] = pad_sequences(combinedDF[\"tokenGroupCode\"], maxlen = maxLen, padding = \"post\", truncating = \"post\").tolist()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/Model%20Creation%201.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m (combinedDF)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1132\u001b[0m, in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTruncating type \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtruncating\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m not understood\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# check `trunc` has expected shape\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m trunc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(trunc, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1133\u001b[0m \u001b[39mif\u001b[39;00m trunc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:] \u001b[39m!=\u001b[39m sample_shape:\n\u001b[1;32m   1134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1135\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of sample \u001b[39m\u001b[39m{\u001b[39;00mtrunc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m of sequence at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mposition \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m is different from expected shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1137\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msample_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1138\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ' 28 28 28 28 28 28 28 28 28 156 18 2 11 42 1 5 8 775 159 538 386 118 4 2 1 3 7 2 52 17 118 1 5 605 358 118 4 2 1 3 6 2 118 315 1 3 6 123 142 5 2 212 1 5 55 4 2 9 1 3 55 4 2 212 9 1 3 4 2 2 11 40 42 1"
          ]
        }
      ],
      "source": [
        "#Padding\n",
        "\n",
        "maxLen = 500\n",
        "minLen = 100\n",
        "#get rid of the ones that are too long\n",
        "\n",
        "print (type(combinedDF[\"tokenCode\"]))\n",
        "combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) <= maxLen -1]\n",
        "\n",
        "#shorten the ones that are too long FOR TESTING\n",
        "#combinedDF[\"tokenCode\"] = combinedDF[\"tokenCode\"].apply(lambda x: [int(i) for i in x.split()[:maxLen]])\n",
        "\n",
        "#get rid of the ones that are too short DISABLED FOR TESTING\n",
        "#combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) > minLen]\n",
        "\n",
        "#Pad the sequences\n",
        "combinedDF[\"tokenCode\"] = combinedDF[\"tokenCode\"].apply(lambda x: [int(i) for i in x.split()]).tolist()\n",
        "combinedDF[\"tokenCode\"] = pad_sequences(combinedDF[\"tokenCode\"].tolist(), maxlen=maxLen, padding=\"post\", truncating=\"post\").tolist()\n",
        "#combinedDF[\"tokenGroupCode\"] = pad_sequences(combinedDF[\"tokenGroupCode\"], maxlen = maxLen, padding = \"post\", truncating = \"post\").tolist()\n",
        "\n",
        "print(combinedDF)\n",
        "\n",
        "#only use 5% of the data\n",
        "#combinedDF = combinedDF.sample(frac=0.001, random_state=1)\n",
        "\n",
        "#48590 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               tokenCode  \\\n",
            "3       28 28 28 28 28 28 28 28 28 156 18 2 11 42 1 5...   \n",
            "11      8 280 2 118 1 120 8 280 2 118 1 120 8 396 15 ...   \n",
            "12      8 280 2 118 1 120 8 396 15 496 398 15 782 8 8...   \n",
            "14      8 280 2 118 1 120 8 280 2 118 1 120 8 396 15 ...   \n",
            "17      8 280 2 118 1 120 8 280 2 118 1 120 8 396 15 ...   \n",
            "...                                                  ...   \n",
            "48409   45 19 718 280 2 489 1 41 39 381 280 2 489 1 1...   \n",
            "48417   28 18 2 11 358 1 8 8 8 8 8 8 8 5 63 42 3 3 2 ...   \n",
            "48426   28 8 15 8 358 149 192 51 306 8 50 3 28 28 28 ...   \n",
            "48430   45 12 47 19 324 86 12 267 114 19 12 114 47 19...   \n",
            "48431   28 8 15 8 358 149 192 51 306 8 50 3 28 28 28 ...   \n",
            "\n",
            "                                                    Path  fileGrade  \n",
            "3         3265841/app/src/main/cpp/passman-lib.cpp/0.cpp  40.400000  \n",
            "11         3378387/src/zmq/zmqabstractnotifier.cpp/0.cpp  25.600000  \n",
            "12         3378387/src/zmq/zmqabstractnotifier.cpp/2.cpp  38.933333  \n",
            "14         3378387/src/zmq/zmqabstractnotifier.cpp/1.cpp  32.266667  \n",
            "17                      3378387/src/policy/rbf.cpp/0.cpp  25.600000  \n",
            "...                                                  ...        ...  \n",
            "48409  3397270/extras/LEDs_Autoprog/UserInterface.cpp...  35.800000  \n",
            "48417     3397270/extras/LEDs_Autoprog/Helpers.cpp/0.cpp  22.800000  \n",
            "48426  3397270/examples/80.Modules/02.CharlieplexTiny...  25.800000  \n",
            "48430  3397270/examples/80.Modules/02.CharlieplexTiny...  19.800000  \n",
            "48431  3397270/examples/80.Modules/02.CharlieplexTiny...  19.800000  \n",
            "\n",
            "[23194 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print (combinedDF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nu6hyuey05pU",
        "outputId": "2d9cf582-6a4a-46ad-e21c-e84a8f2eecce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 4s 4s/step - loss: 5.0923 - mse: 198.4853 - mae: 10.5346 - mape: 237599.4531 - accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0614 - mse: 198.2984 - mae: 10.5277 - mape: 1296218.1250 - accuracy: 0.1667\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0220 - mse: 198.0753 - mae: 10.5215 - mape: 3719304.0000 - accuracy: 0.1667\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9783 - mse: 197.8449 - mae: 10.5129 - mape: 5437255.5000 - accuracy: 0.1667\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9209 - mse: 197.4838 - mae: 10.5027 - mape: 7042212.5000 - accuracy: 0.1667\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8608 - mse: 197.1545 - mae: 10.4890 - mape: 8628477.0000 - accuracy: 0.1667\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8247 - mse: 196.9326 - mae: 10.4830 - mape: 11425679.0000 - accuracy: 0.1667\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7495 - mse: 196.4975 - mae: 10.4671 - mape: 14189411.0000 - accuracy: 0.1667\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6815 - mse: 196.0252 - mae: 10.4566 - mape: 19125696.0000 - accuracy: 0.1667\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5773 - mse: 195.3310 - mae: 10.4317 - mape: 21449634.0000 - accuracy: 0.1667\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4967 - mse: 194.8594 - mae: 10.4145 - mape: 27034096.0000 - accuracy: 0.1667\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4103 - mse: 194.2302 - mae: 10.3951 - mape: 31535770.0000 - accuracy: 0.1667\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2704 - mse: 193.0946 - mae: 10.3578 - mape: 34969864.0000 - accuracy: 0.1667\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1355 - mse: 192.0103 - mae: 10.3289 - mape: 40302884.0000 - accuracy: 0.1667\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9744 - mse: 190.8537 - mae: 10.2858 - mape: 58329892.0000 - accuracy: 0.1667\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8391 - mse: 189.5554 - mae: 10.2376 - mape: 60072148.0000 - accuracy: 0.1667\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6870 - mse: 188.1512 - mae: 10.1885 - mape: 72124424.0000 - accuracy: 0.1667\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5122 - mse: 186.5796 - mae: 10.1230 - mape: 86096016.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2794 - mse: 183.5561 - mae: 10.0433 - mape: 112230184.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0265 - mse: 180.6122 - mae: 9.9224 - mape: 114231224.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8946 - mse: 178.7186 - mae: 9.8662 - mape: 129657336.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6190 - mse: 174.1498 - mae: 9.6973 - mape: 154014896.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5203 - mse: 172.4347 - mae: 9.6188 - mape: 178153408.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3408 - mse: 168.1044 - mae: 9.5491 - mape: 217377344.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1110 - mse: 162.8710 - mae: 9.3826 - mape: 259662800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8887 - mse: 156.8210 - mae: 9.2751 - mape: 258207920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7599 - mse: 151.3451 - mae: 9.1741 - mape: 344335712.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6585 - mse: 147.2951 - mae: 9.0581 - mape: 373867104.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5887 - mse: 144.9997 - mae: 8.9225 - mape: 395115104.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5625 - mse: 140.8395 - mae: 8.8926 - mape: 516301856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4386 - mse: 133.2236 - mae: 8.7305 - mape: 537559104.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4143 - mse: 128.1290 - mae: 8.6405 - mape: 643573952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3355 - mse: 122.4428 - mae: 8.5382 - mape: 632091840.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2694 - mse: 120.3147 - mae: 8.2712 - mape: 609118272.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3211 - mse: 115.3952 - mae: 8.1835 - mape: 824452032.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3382 - mse: 115.4699 - mae: 8.3312 - mape: 804889600.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2840 - mse: 109.5588 - mae: 8.0537 - mape: 840540160.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3483 - mse: 106.8340 - mae: 8.1765 - mape: 968093952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2272 - mse: 98.3196 - mae: 7.7141 - mape: 942692800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2666 - mse: 99.0624 - mae: 7.7989 - mape: 988104128.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2768 - mse: 95.9060 - mae: 7.7206 - mape: 1052837952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3054 - mse: 99.5354 - mae: 7.7475 - mape: 1022905920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1892 - mse: 90.1801 - mae: 7.3712 - mape: 1019511552.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3181 - mse: 96.6764 - mae: 7.7805 - mape: 1109615488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2685 - mse: 92.1289 - mae: 7.6231 - mape: 1084456448.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3346 - mse: 100.4989 - mae: 7.9271 - mape: 1085217152.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2723 - mse: 95.2767 - mae: 7.8528 - mape: 1017487040.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3218 - mse: 93.4046 - mae: 7.7258 - mape: 1153787008.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3130 - mse: 96.3089 - mae: 7.8398 - mape: 1099264640.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2798 - mse: 90.2563 - mae: 7.6592 - mape: 1105131392.0000 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2514 - mse: 90.5807 - mae: 7.6758 - mape: 1032363456.0000 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2511 - mse: 88.4403 - mae: 7.4945 - mape: 1121123200.0000 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1787 - mse: 88.7958 - mae: 7.3430 - mape: 1002208256.0000 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2010 - mse: 91.2462 - mae: 7.5755 - mape: 982585920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2534 - mse: 91.4093 - mae: 7.6050 - mape: 1054859840.0000 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2044 - mse: 91.6447 - mae: 7.4816 - mape: 959233728.0000 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2117 - mse: 88.6899 - mae: 7.4386 - mape: 1026295488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1648 - mse: 93.4124 - mae: 7.5425 - mape: 879519552.0000 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2359 - mse: 93.2604 - mae: 7.5059 - mape: 1024259520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1946 - mse: 93.4121 - mae: 7.5456 - mape: 914660800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2761 - mse: 101.5049 - mae: 7.7394 - mape: 947748096.0000 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1758 - mse: 95.4111 - mae: 7.5815 - mape: 886193920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1647 - mse: 94.0585 - mae: 7.4805 - mape: 857650432.0000 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1585 - mse: 98.4124 - mae: 7.7075 - mape: 762290112.0000 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1372 - mse: 96.0822 - mae: 7.5961 - mape: 761149888.0000 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1109 - mse: 99.2352 - mae: 7.5999 - mape: 669783616.0000 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0785 - mse: 93.9072 - mae: 7.4816 - mape: 726335744.0000 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1194 - mse: 99.6680 - mae: 7.5648 - mape: 743596480.0000 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0553 - mse: 95.6659 - mae: 7.5952 - mape: 631265216.0000 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0809 - mse: 97.5073 - mae: 7.6696 - mape: 660955904.0000 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9996 - mse: 94.0216 - mae: 7.4396 - mape: 629603328.0000 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9799 - mse: 94.3755 - mae: 7.5221 - mape: 538195328.0000 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0436 - mse: 97.7087 - mae: 7.4939 - mape: 625491904.0000 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9924 - mse: 95.5888 - mae: 7.4469 - mape: 582535424.0000 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9530 - mse: 95.6393 - mae: 7.3885 - mape: 526571296.0000 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9741 - mse: 97.1671 - mae: 7.4219 - mape: 565115328.0000 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9313 - mse: 94.2257 - mae: 7.3963 - mape: 498615840.0000 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8761 - mse: 88.1894 - mae: 7.1318 - mape: 534070528.0000 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8863 - mse: 91.3753 - mae: 7.2152 - mape: 491531488.0000 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8341 - mse: 88.3300 - mae: 7.0932 - mape: 439265024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8721 - mse: 93.9304 - mae: 7.3041 - mape: 443305856.0000 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8457 - mse: 86.8846 - mae: 7.1718 - mape: 461812864.0000 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7791 - mse: 82.8852 - mae: 6.8198 - mape: 431492256.0000 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7868 - mse: 86.6941 - mae: 7.1851 - mape: 355992928.0000 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.8436 - mse: 89.2226 - mae: 7.1646 - mape: 427272992.0000 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7558 - mse: 88.1442 - mae: 6.9398 - mape: 331512608.0000 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6797 - mse: 80.7054 - mae: 6.7438 - mape: 305132448.0000 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7359 - mse: 78.8136 - mae: 6.7480 - mape: 391661280.0000 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7248 - mse: 84.0667 - mae: 6.8681 - mape: 304037024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7234 - mse: 82.1762 - mae: 6.7914 - mape: 311233504.0000 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6487 - mse: 74.9841 - mae: 6.5890 - mape: 306667776.0000 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6129 - mse: 71.9302 - mae: 6.4204 - mape: 279805696.0000 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6104 - mse: 72.4568 - mae: 6.3521 - mape: 311073056.0000 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6297 - mse: 72.2691 - mae: 6.4675 - mape: 291823104.0000 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6207 - mse: 77.0963 - mae: 6.5170 - mape: 273998368.0000 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5432 - mse: 67.8598 - mae: 6.1244 - mape: 230832512.0000 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5344 - mse: 70.6595 - mae: 6.1748 - mape: 212114928.0000 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5712 - mse: 70.6961 - mae: 6.2938 - mape: 209915248.0000 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6015 - mse: 70.2818 - mae: 6.3731 - mape: 226210160.0000 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4910 - mse: 63.0247 - mae: 5.9808 - mape: 153290032.0000 - accuracy: 0.0000e+00\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/.gitignore\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/TokenizerManager.py\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/.DS_Store\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/main.py\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/.git\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/CaMlSupportingClasses.py\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/__pycache__/\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/__pycache__/CLPTokenizer.cpython-310.pyc\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/__pycache__/CaMlSupportingClasses.cpython-310.pyc\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/SCA-Tokenizer/CLPTokenizer.py\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/../Auto-Grader/\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/../Auto-Grader/Grader.py\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/../Auto-Grader/SupportingClasses/\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/../Auto-Grader/SupportingClasses/CaMlSupportingClasses.py\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/../Auto-Grader/SupportingClasses/__pycache__/\n",
            "/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/../Auto-Grader/SupportingClasses/__pycache__/CaMlSupportingClasses.cpython-310.pyc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaredrussell/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "tar: Removing leading `/' from member names\n",
            "tar: Removing leading `/home/jaredrussell/gitRepos/SCA-ML-grade/Model-Generation/../' from member names\n"
          ]
        }
      ],
      "source": [
        "#if (not gpu_detected):\n",
        "#    print(\"GPU not detected, using CPU\")\n",
        "\n",
        "number_of_tokens = combinedDF[\"tokenCode\"].apply(lambda x: len(x)).max()\n",
        "print (number_of_tokens)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(number_of_tokens, 64, input_length=maxLen))\n",
        "model.add(layers.Conv1D(64, 3, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Reshape((1, 64)))\n",
        "model.add(layers.Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.38479930887149405))\n",
        "model.add(layers.Bidirectional(LSTM(32)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_logarithmic_error', optimizer='Adam', metrics=['mse', 'mae', 'mape', 'accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# convert inputs to numpy arrays\n",
        "token_code = np.array(combinedDF[\"tokenCode\"].tolist())\n",
        "#token_group_code = np.array(combinedDF[\"tokenGroupCode\"].tolist())\n",
        "file_grade = np.array(combinedDF[\"fileGrade\"].tolist())\n",
        "\n",
        "hist = model.fit(token_code, file_grade, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "\n",
        "#Save the model in timestamp folder and with tokenizer\n",
        "timestamp = str(pd.Timestamp.now()).replace(\" \", \"_\").replace(\":\", \"-\").replace(\".\", \"-\")\n",
        "if not os.path.exists(modelOutputPath):\n",
        "    os.mkdir(modelOutputPath)\n",
        "if not os.path.exists(modelOutputPath + \"/\" + timestamp):\n",
        "    os.mkdir(modelOutputPath + \"/\" + timestamp)\n",
        "model.save(modelOutputPath + \"/\" + timestamp + \"/model.h5\")\n",
        "with open(modelOutputPath + \"/\" + timestamp + \"/tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "#make an archaive of the SCA-Tokenizer Folder\n",
        "#get CWD\n",
        "cwd = os.getcwd()\n",
        "if os.path.exists(os.path.join(cwd, \"SCA-Tokenizer\")):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/SCA-Tokenizer.tar.gz\\\" \" + os.path.join(cwd, \"SCA-Tokenizer\"))\n",
        "\n",
        "#Save the AutoGrader Folder\n",
        "autoGraderDir = os.path.join(cwd, \"../Auto-Grader/\")\n",
        "if os.path.exists(autoGraderDir):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/Auto-Grader.tar.gz\\\" \" + autoGraderDir)\n",
        "\n",
        "#Save tokenizedGroupData\n",
        "#with open(modelOutputPath + \"/\" + timestamp + \"/tokenizedGroupDataframe.pkl\", \"wb\") as f:\n",
        "#    pickle.dump(tokenizedGroupData, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
