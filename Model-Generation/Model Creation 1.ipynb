{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BFlZYHLP1AyZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def homePath(path):\n",
        "    if path[0] == \"~\":\n",
        "        return os.path.join(os.path.expanduser(\"~\"), path.strip(\"~/\"))\n",
        "    else:\n",
        "        return path\n",
        "\n",
        "#Model Creation 1\n",
        "#Figure out how to do versioning effectively\n",
        "individualInput = False\n",
        "combinedInputPath = \"/mnt/SPDrive/SPGenerations/\"\n",
        "pathToTokenizedData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Tokenizer\\\\\"\n",
        "pathToGradeData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Grader\\\\\"\n",
        "GradesTokensName = \"\"\n",
        "\n",
        "\n",
        "if not individualInput:\n",
        "    pathToTokenizedData = os.path.join(combinedInputPath, \"Tokens/\")\n",
        "    pathToGradeData = os.path.join(combinedInputPath, \"Grades/\")\n",
        "\n",
        "if GradesTokensName == \"\":\n",
        "    #Use newest folder for each\n",
        "\n",
        "    #Get the newest folder for the tokens\n",
        "    tokensFolders = os.listdir(pathToTokenizedData)\n",
        "    tokensFolders.sort()\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData , tokensFolders[-1])\n",
        "\n",
        "    #Get the newest folder for the grades\n",
        "    gradesFolders = os.listdir(pathToGradeData)\n",
        "    gradesFolders.sort()\n",
        "    pathToGradeData = os.path.join(pathToGradeData,  gradesFolders[-1])\n",
        "else:\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData, GradesTokensName)\n",
        "    pathToGradeData = os.path.join(pathToGradeData, GradesTokensName)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "modelOutputPath = \"/mnt/SPDrive/SPGenerations/Models/\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nLHjdZFH05pS",
        "outputId": "1016b38b-0f18-42e3-8e28-1e03019b46a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tokenCode  \\\n",
            "0       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "1       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "2       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "3       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "4       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "...                                                   ...   \n",
            "220785  [27, 712, 43, 279, 27, 279, 27, 1, 27, 264, 43...   \n",
            "220786  [27, 712, 43, 279, 27, 279, 27, 1, 27, 264, 43...   \n",
            "220787  [43, 279, 27, 279, 27, 1, 27, 264, 43, 1, 27, ...   \n",
            "220788  [27, 712, 43, 279, 27, 279, 27, 1, 27, 264, 43...   \n",
            "220789  [27, 712, 43, 279, 27, 279, 27, 1, 27, 264, 43...   \n",
            "\n",
            "                                                     Path  fileGrade  \n",
            "0       3722273/examples/basics/linear_regression.py/1.py  59.000000  \n",
            "1       3722273/examples/basics/linear_regression.py/3.py  67.000000  \n",
            "2       3722273/examples/basics/linear_regression.py/2.py  66.000000  \n",
            "3       3722273/examples/basics/linear_regression.py/0.py  55.000000  \n",
            "4       3722273/examples/basics/linear_regression.py/4.py  71.000000  \n",
            "...                                                   ...        ...  \n",
            "220785                     3912822/article_maker.py/10.py  71.666667  \n",
            "220786                      3912822/article_maker.py/9.py  70.000000  \n",
            "220787                      3912822/article_maker.py/2.py  58.333333  \n",
            "220788                      3912822/article_maker.py/6.py  65.000000  \n",
            "220789                      3912822/article_maker.py/7.py  66.666667  \n",
            "\n",
            "[220790 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "import keras.layers as layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "#Load the data\n",
        "#tokenized data is in tokenizedData.pkl, has tokenizer obj in tokenizer.json\n",
        "\n",
        "#Load the tokenizer\n",
        "with open(pathToTokenizedData+ \"/tokenizer.json\", \"r\") as f:\n",
        "    tokenizer = tokenizer_from_json(f.read())\n",
        "\n",
        "\n",
        "\n",
        "#Load the tokenized data\n",
        "with open(pathToTokenizedData + \"/tokenizedData.pkl\", \"rb\") as f:\n",
        "    tokenizedData = pickle.load(f)\n",
        "\n",
        "#Load the grade data\n",
        "#gradeData is a dict with keys as the file names and values as the grades\n",
        "with open(pathToGradeData + \"/grades.pkl\", \"rb\") as f:\n",
        "    gradeData = pickle.load(f)\n",
        "\n",
        "combinedDF = pd.merge(tokenizedData, gradeData, on = \"Path\")\n",
        "print (combinedDF)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jnja4-p705pU",
        "outputId": "b79f4a7d-57af-4836-e052-f2089eaec5b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tokenCode  \\\n",
            "0       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "1       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "2       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "3       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "4       [9, 43, 427, 27, 612, 5, 756, 5, 656, 27, 1, 3...   \n",
            "...                                                   ...   \n",
            "220779  [43, 427, 27, 1, 27, 264, 27, 82, 3, 20, 8, 9,...   \n",
            "220780  [43, 427, 27, 1, 27, 82, 3, 20, 8, 9, 3, 23, 8...   \n",
            "220781  [43, 427, 27, 1, 27, 264, 27, 82, 3, 20, 8, 9,...   \n",
            "220782  [43, 427, 27, 1, 27, 82, 3, 20, 8, 9, 3, 23, 8...   \n",
            "220783  [43, 427, 27, 1, 27, 264, 27, 82, 3, 20, 8, 9,...   \n",
            "\n",
            "                                                     Path  fileGrade  \n",
            "0       3722273/examples/basics/linear_regression.py/1.py  59.000000  \n",
            "1       3722273/examples/basics/linear_regression.py/3.py  67.000000  \n",
            "2       3722273/examples/basics/linear_regression.py/2.py  66.000000  \n",
            "3       3722273/examples/basics/linear_regression.py/0.py  55.000000  \n",
            "4       3722273/examples/basics/linear_regression.py/4.py  71.000000  \n",
            "...                                                   ...        ...  \n",
            "220779                       3912822/pelicanconf.py/41.py  76.471698  \n",
            "220780                       3912822/pelicanconf.py/18.py  61.792453  \n",
            "220781                       3912822/pelicanconf.py/39.py  69.716981  \n",
            "220782                       3912822/pelicanconf.py/25.py  64.433962  \n",
            "220783                       3912822/pelicanconf.py/45.py  71.981132  \n",
            "\n",
            "[41531 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#Padding\n",
        "\n",
        "maxLen = 500\n",
        "minLen = 100\n",
        "#get rid of the ones that are too long\n",
        "combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) <= maxLen]\n",
        "\n",
        "#get rid of the ones that are too short\n",
        "combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) > minLen]\n",
        "\n",
        "#Pad the sequences\n",
        "combinedDF[\"tokenCode\"] = pad_sequences(combinedDF[\"tokenCode\"], maxlen = maxLen, padding = \"post\", truncating = \"post\").tolist()\n",
        "\n",
        "print (combinedDF)\n",
        "\n",
        "#48590 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2-_lF4pW05pU",
        "outputId": "0568f4dd-be12-4884-c67e-9e8592184df6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#create a chart of the grades\n",
        "graph = plt.hist(combinedDF['fileGrade'], bins=20, range=(0, 100))\n",
        "plt.xticks([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100])\n",
        "plt.xlabel(\"Grade Range\")\n",
        "plt.ylabel(\"Number of Commits\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M55w1Ku405pU",
        "outputId": "937ea050-b42a-444b-bb43-11c6f48c7f33"
      },
      "outputs": [],
      "source": [
        "#test to make sure gpu is detected and save as bool\n",
        "gpu_detected = tf.test.is_gpu_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nu6hyuey05pU",
        "outputId": "2d9cf582-6a4a-46ad-e21c-e84a8f2eecce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-02 02:15:23.005678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 364 MB memory:  -> device: 0, name: NVIDIA A2, pci bus id: 0000:11:00.0, compute capability: 8.6\n",
            "2023-11-02 02:15:23.006674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 12935 MB memory:  -> device: 1, name: NVIDIA A2, pci bus id: 0000:b1:00.0, compute capability: 8.6\n",
            "2023-11-02 02:15:23.983788: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 1024)         819200    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 498, 2048)         6293504   \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 2048)              0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 2048)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 1, 2048)           25174016  \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 2048)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 1024)              10489856  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 2049      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44877825 (171.20 MB)\n",
            "Trainable params: 44877825 (171.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-02 02:56:57.590896: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 158.43MiB (rounded to 166124032)requested by op _EagerConst\n",
            "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
            "Current allocation summary follows.\n",
            "Current allocation summary follows.\n",
            "2023-11-02 02:56:57.590945: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
            "2023-11-02 02:56:57.590966: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 22, Chunks in use: 22. 5.5KiB allocated for chunks. 5.5KiB in use in bin. 96B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.590978: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.590990: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 2.5KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591001: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591011: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591023: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 5, Chunks in use: 5. 44.0KiB allocated for chunks. 44.0KiB in use in bin. 40.0KiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591035: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 3, Chunks in use: 2. 48.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591045: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591054: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591063: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591073: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591083: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 984.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591094: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591105: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 3.12MiB allocated for chunks. 3.12MiB in use in bin. 3.12MiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591117: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 12.19MiB allocated for chunks. 12.19MiB in use in bin. 8.00MiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591129: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 3, Chunks in use: 1. 24.00MiB allocated for chunks. 8.00MiB in use in bin. 8.00MiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591141: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 6, Chunks in use: 5. 104.00MiB allocated for chunks. 88.00MiB in use in bin. 88.00MiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591153: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 2. 64.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591162: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591173: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 154.68MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591183: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2023-11-02 02:56:57.591194: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 158.43MiB was 128.00MiB, Chunk State: \n",
            "2023-11-02 02:56:57.591216: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 154.68MiB | Requested Size: 0B | in_use: 0 | bin_num: 19, prev:   Size: 32.00MiB | Requested Size: 32.00MiB | in_use: 1 | bin_num: -1\n",
            "2023-11-02 02:56:57.591224: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 381747200\n",
            "2023-11-02 02:56:57.591233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000000 of size 256 next 1\n",
            "2023-11-02 02:56:57.591241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000100 of size 1280 next 2\n",
            "2023-11-02 02:56:57.591248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000600 of size 256 next 3\n",
            "2023-11-02 02:56:57.591255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000700 of size 256 next 4\n",
            "2023-11-02 02:56:57.591262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000800 of size 256 next 6\n",
            "2023-11-02 02:56:57.591269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000900 of size 256 next 7\n",
            "2023-11-02 02:56:57.591276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000a00 of size 256 next 11\n",
            "2023-11-02 02:56:57.591283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658000b00 of size 8192 next 5\n",
            "2023-11-02 02:56:57.591291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658002b00 of size 256 next 8\n",
            "2023-11-02 02:56:57.591298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658002c00 of size 256 next 14\n",
            "2023-11-02 02:56:57.591304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658002d00 of size 256 next 15\n",
            "2023-11-02 02:56:57.591311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658002e00 of size 256 next 16\n",
            "2023-11-02 02:56:57.591318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658002f00 of size 256 next 22\n",
            "2023-11-02 02:56:57.591325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003000 of size 256 next 29\n",
            "2023-11-02 02:56:57.591332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003100 of size 256 next 38\n",
            "2023-11-02 02:56:57.591339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003200 of size 256 next 33\n",
            "2023-11-02 02:56:57.591346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003300 of size 256 next 39\n",
            "2023-11-02 02:56:57.591353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003400 of size 256 next 40\n",
            "2023-11-02 02:56:57.591360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003500 of size 256 next 44\n",
            "2023-11-02 02:56:57.591366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003600 of size 256 next 41\n",
            "2023-11-02 02:56:57.591373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003700 of size 256 next 43\n",
            "2023-11-02 02:56:57.591380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003800 of size 256 next 47\n",
            "2023-11-02 02:56:57.591387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003900 of size 256 next 48\n",
            "2023-11-02 02:56:57.591395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f9658003a00 of size 1280 next 21\n",
            "2023-11-02 02:56:57.591402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658003f00 of size 256 next 19\n",
            "2023-11-02 02:56:57.591409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658004000 of size 12288 next 20\n",
            "2023-11-02 02:56:57.591418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658007000 of size 16384 next 24\n",
            "2023-11-02 02:56:57.591425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965800b000 of size 16384 next 25\n",
            "2023-11-02 02:56:57.591432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965800f000 of size 8192 next 31\n",
            "2023-11-02 02:56:57.591439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658011000 of size 8192 next 34\n",
            "2023-11-02 02:56:57.591446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f9658013000 of size 16384 next 46\n",
            "2023-11-02 02:56:57.591454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658017000 of size 8192 next 45\n",
            "2023-11-02 02:56:57.591462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f9658019000 of size 1007616 next 30\n",
            "2023-11-02 02:56:57.591469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965810f000 of size 5446400 next 9\n",
            "2023-11-02 02:56:57.591477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658640b00 of size 3276800 next 10\n",
            "2023-11-02 02:56:57.591485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9658960b00 of size 16777216 next 32\n",
            "2023-11-02 02:56:57.591492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9659960b00 of size 16777216 next 35\n",
            "2023-11-02 02:56:57.591499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f965a960b00 of size 1048576 next 36\n",
            "2023-11-02 02:56:57.591506: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965aa60b00 of size 7340032 next 37\n",
            "2023-11-02 02:56:57.591513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f965b160b00 of size 8388608 next 13\n",
            "2023-11-02 02:56:57.591521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965b960b00 of size 25165824 next 12\n",
            "2023-11-02 02:56:57.591528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965d160b00 of size 16777216 next 23\n",
            "2023-11-02 02:56:57.591535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f965e160b00 of size 8388608 next 42\n",
            "2023-11-02 02:56:57.591542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965e960b00 of size 8388608 next 18\n",
            "2023-11-02 02:56:57.591550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f965f160b00 of size 33554432 next 17\n",
            "2023-11-02 02:56:57.591557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9661160b00 of size 16777216 next 28\n",
            "2023-11-02 02:56:57.591564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f9662160b00 of size 16777216 next 27\n",
            "2023-11-02 02:56:57.591571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9663160b00 of size 33554432 next 26\n",
            "2023-11-02 02:56:57.591579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f9665160b00 of size 162198784 next 18446744073709551615\n",
            "2023-11-02 02:56:57.591586: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
            "2023-11-02 02:56:57.591595: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 22 Chunks of size 256 totalling 5.5KiB\n",
            "2023-11-02 02:56:57.591604: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
            "2023-11-02 02:56:57.591613: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 8192 totalling 32.0KiB\n",
            "2023-11-02 02:56:57.591621: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12288 totalling 12.0KiB\n",
            "2023-11-02 02:56:57.591630: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 16384 totalling 32.0KiB\n",
            "2023-11-02 02:56:57.591638: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3276800 totalling 3.12MiB\n",
            "2023-11-02 02:56:57.591646: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5446400 totalling 5.19MiB\n",
            "2023-11-02 02:56:57.591654: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7340032 totalling 7.00MiB\n",
            "2023-11-02 02:56:57.591662: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 8388608 totalling 8.00MiB\n",
            "2023-11-02 02:56:57.591671: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 16777216 totalling 64.00MiB\n",
            "2023-11-02 02:56:57.591679: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25165824 totalling 24.00MiB\n",
            "2023-11-02 02:56:57.591688: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 33554432 totalling 64.00MiB\n",
            "2023-11-02 02:56:57.591697: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 175.40MiB\n",
            "2023-11-02 02:56:57.591706: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 381747200 memory_limit_: 381747200 available bytes: 0 curr_region_allocation_bytes_: 763494400\n",
            "2023-11-02 02:56:57.591721: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
            "Limit:                       381747200\n",
            "InUse:                       183920128\n",
            "MaxInUse:                    201715456\n",
            "NumAllocs:                         137\n",
            "MaxAllocSize:                 50331648\n",
            "Reserved:                            0\n",
            "PeakReserved:                        0\n",
            "LargestFreeBlock:                    0\n",
            "\n",
            "2023-11-02 02:56:57.591735: W tensorflow/tsl/framework/bfc_allocator.cc:497] *************x_************_*****************___**********__________________________________________\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m/home/mcall/SPGit/Model-Generation/Model Creation 1.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Berica/home/mcall/SPGit/Model-Generation/Model%20Creation%201.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Berica/home/mcall/SPGit/Model-Generation/Model%20Creation%201.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_logarithmic_error\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmape\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://tunnel%2Berica/home/mcall/SPGit/Model-Generation/Model%20Creation%201.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(combinedDF[\u001b[39m\"\u001b[39;49m\u001b[39mtokenCode\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), combinedDF[\u001b[39m\"\u001b[39;49m\u001b[39mfileGrade\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Berica/home/mcall/SPGit/Model-Generation/Model%20Creation%201.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#Save the model in timestamp folder and with tokenizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Berica/home/mcall/SPGit/Model-Generation/Model%20Creation%201.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m timestamp \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(pd\u001b[39m.\u001b[39mTimestamp\u001b[39m.\u001b[39mnow())\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ],
      "source": [
        "#if (not gpu_detected):\n",
        "#    print(\"GPU not detected, using CPU\")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(tokenizer.num_words, 1024, input_length=maxLen))\n",
        "model.add(layers.Conv1D(2048, 3, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Reshape((1, 2048)))\n",
        "model.add(layers.Bidirectional(LSTM(1024, return_sequences=True)))\n",
        "model.add(Dropout(0.38479930887149405))\n",
        "model.add(layers.Bidirectional(LSTM(512)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss='mean_squared_logarithmic_error', optimizer='Adam', metrics=['mse', 'mae', 'mape', 'accuracy'])\n",
        "\n",
        "hist = model.fit(combinedDF[\"tokenCode\"].tolist(), combinedDF[\"fileGrade\"].tolist(), epochs=100, batch_size=32,verbose = 1)\n",
        "\n",
        "\n",
        "\n",
        "#Save the model in timestamp folder and with tokenizer\n",
        "timestamp = str(pd.Timestamp.now()).replace(\" \", \"_\").replace(\":\", \"-\").replace(\".\", \"-\")\n",
        "if not os.path.exists(modelOutputPath):\n",
        "    os.mkdir(modelOutputPath)\n",
        "if not os.path.exists(modelOutputPath + \"/\" + timestamp):\n",
        "    os.mkdir(modelOutputPath + \"/\" + timestamp)\n",
        "model.save(modelOutputPath + \"/\" + timestamp + \"/model.h5\")\n",
        "with open(modelOutputPath + \"/\" + timestamp + \"/tokenizer.json\", \"w\") as f:\n",
        "    f.write(tokenizer.to_json())\n",
        "#make an archaive of the SCA-Tokenizer Folder\n",
        "#get CWD\n",
        "cwd = os.getcwd()\n",
        "if os.path.exists(os.path.join(cwd, \"SCA-Tokenizer\")):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/SCA-Tokenizer.tar.gz\\\" \" + os.path.join(cwd, \"SCA-Tokenizer\"))\n",
        "\n",
        "#Save the AutoGrader Folder\n",
        "autoGraderDir = os.path.join(cwd, \"../Auto-Grader/\")\n",
        "if os.path.exists(autoGraderDir):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/Auto-Grader.tar.gz\\\" \" + autoGraderDir)\n",
        "\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.title('Loss')\n",
        "plt.plot(hist.history['loss'], label='train')\n",
        "plt.plot(hist.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "# plot accuracy during training\n",
        "plt.subplot(212)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(hist.history['accuracy'], label='train')\n",
        "plt.plot(hist.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Save the model in timestamp folder and with tokenizer\n",
        "timestamp = str(pd.Timestamp.now()).replace(\" \", \"_\").replace(\":\", \"-\").replace(\".\", \"-\")\n",
        "if not os.path.exists(modelOutputPath):\n",
        "    os.mkdir(modelOutputPath)\n",
        "if not os.path.exists(modelOutputPath + \"/\" + timestamp):\n",
        "    os.mkdir(modelOutputPath + \"/\" + timestamp)\n",
        "model.save(modelOutputPath + \"/\" + timestamp + \"/model.h5\")\n",
        "with open(modelOutputPath + \"/\" + timestamp + \"/tokenizer.json\", \"w\") as f:\n",
        "    f.write(tokenizer.to_json())\n",
        "#make an archaive of the SCA-Tokenizer Folder\n",
        "#get CWD\n",
        "cwd = os.getcwd()\n",
        "if os.path.exists(os.path.join(cwd, \"SCA-Tokenizer\")):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/SCA-Tokenizer.tar.gz\\\" \" + os.path.join(cwd, \"SCA-Tokenizer\"))\n",
        "\n",
        "#Save the AutoGrader Folder\n",
        "autoGraderDir = os.path.join(cwd, \"../Auto-Grader/\")\n",
        "if os.path.exists(autoGraderDir):\n",
        "    os.system(\"tar -czvf \\\"\" + modelOutputPath + \"/\" + timestamp + \"/Auto-Grader.tar.gz\\\" \" + autoGraderDir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "timestamp = str(pd.Timestamp.now()).replace(\" \", \"_\").replace(\":\", \"-\").replace(\".\", \"-\")\n",
        "if not os.path.exists(modelOutputPath):\n",
        "    os.mkdir(modelOutputPath)\n",
        "if not os.path.exists(modelOutputPath + \"/\" + timestamp):\n",
        "    os.mkdir(modelOutputPath + \"/\" + timestamp)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
