{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BFlZYHLP1AyZ"
      },
      "outputs": [],
      "source": [
        "combinedInputPath = \"/mnt/SPDrive/SPGenerations/\" #The path to the folder containing the tokenized and graded data. If individualInput is true, this will be ignored\n",
        "\n",
        "individualInput = False #If true, the program will use the individual input paths below. If false, it will use the combinedInputPath above\n",
        "pathToTokenizedData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Tokenizer\\\\\"\n",
        "pathToGradeData = \"C:\\\\Users\\\\mcall\\\\OneDrive\\\\Desktop\\\\DummyOutput\\\\Grader\\\\\"\n",
        "\n",
        "GradesTokensName = \"\" #Specifiy the versions (name) of the grade and token files to use. Leave blank to use the newest version\n",
        "\n",
        "modelOutputPath = \"/home/mcall/SPGenerations/Models/\" #The path to the folder for the model output.\n",
        "\n",
        "import os\n",
        "def homePath(path):\n",
        "    if path[0] == \"~\":\n",
        "        return os.path.join(os.path.expanduser(\"~\"), path.strip(\"~/\"))\n",
        "    else:\n",
        "        return path\n",
        "\n",
        "if not individualInput:\n",
        "    pathToTokenizedData = os.path.join(combinedInputPath, \"Tokens/\")\n",
        "    pathToGradeData = os.path.join(combinedInputPath, \"Grades/\")\n",
        "\n",
        "if GradesTokensName == \"\":\n",
        "    #Use newest folder for each\n",
        "\n",
        "    #Get the newest folder for the tokens\n",
        "    tokensFolders = os.listdir(pathToTokenizedData)\n",
        "    tokensFolders.sort()\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData , tokensFolders[-1])\n",
        "\n",
        "    #Get the newest folder for the grades\n",
        "    gradesFolders = os.listdir(pathToGradeData)\n",
        "    gradesFolders.sort()\n",
        "    pathToGradeData = os.path.join(pathToGradeData,  gradesFolders[-1])\n",
        "else:\n",
        "    pathToTokenizedData = os.path.join(pathToTokenizedData, GradesTokensName)\n",
        "    pathToGradeData = os.path.join(pathToGradeData, GradesTokensName)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nLHjdZFH05pS",
        "outputId": "1016b38b-0f18-42e3-8e28-1e03019b46a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tokenCode  \\\n",
            "0       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "1       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "2       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "3       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "4       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "...                                                   ...   \n",
            "180568  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "180569  [44, 284, 28, 284, 28, 1, 28, 266, 44, 1, 28, ...   \n",
            "180570  [28, 682, 44, 284, 28, 284, 28, 1, 28, 266, 44...   \n",
            "180571  [44, 284, 28, 284, 28, 1, 28, 266, 44, 1, 28, ...   \n",
            "180572  [28, 682, 44, 284, 28, 284, 28, 1, 28, 266, 44...   \n",
            "\n",
            "                                                     Path  fileGrade  \n",
            "0       3722273/examples/basics/linear_regression.py/1.py  59.000000  \n",
            "1       3722273/examples/basics/linear_regression.py/2.py  66.000000  \n",
            "2       3722273/examples/basics/linear_regression.py/3.py  67.000000  \n",
            "3       3722273/examples/basics/linear_regression.py/0.py  55.000000  \n",
            "4       3722273/examples/basics/linear_regression.py/4.py  71.000000  \n",
            "...                                                   ...        ...  \n",
            "180568                       3912822/pelicanconf.py/18.py  61.792453  \n",
            "180569                      3912822/article_maker.py/1.py  56.666667  \n",
            "180570                     3912822/article_maker.py/11.py  73.333333  \n",
            "180571                      3912822/article_maker.py/2.py  58.333333  \n",
            "180572                      3912822/article_maker.py/6.py  65.000000  \n",
            "\n",
            "[180573 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU, Dropout, Bidirectional, Input, Flatten, Concatenate\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "import keras.layers as layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "#Load the data\n",
        "#tokenized data is in tokenizedData.pkl, has tokenizer obj in tokenizer.json\n",
        "\n",
        "#Load the tokenizer\n",
        "with open(pathToTokenizedData+ \"/tokenizer.json\", \"r\") as f:\n",
        "    tokenizer = tokenizer_from_json(f.read())\n",
        "\n",
        "\n",
        "\n",
        "#Load the tokenized data\n",
        "with open(pathToTokenizedData + \"/tokenizedData.pkl\", \"rb\") as f:\n",
        "    tokenizedData = pickle.load(f)\n",
        "\n",
        "#Load the grade data\n",
        "#gradeData is a dict with keys as the file names and values as the grades\n",
        "with open(pathToGradeData + \"/grades.pkl\", \"rb\") as f:\n",
        "    gradeData = pickle.load(f)\n",
        "\n",
        "#load the group data\n",
        "#with open(pathToTokenizedData + \"/tokenGroupDataframe.pkl\", \"rb\") as f:\n",
        "#    tokenizedGroupData = pickle.load(f)\n",
        "\n",
        "combinedDF = pd.merge(tokenizedData, gradeData, on = \"Path\")\n",
        "#combinedDF = pd.merge(combinedDF, tokenizedGroupData, on = \"Path\")\n",
        "print (combinedDF)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "rungraph = False\n",
        "if rungraph:\n",
        "    #chart of token length vs grade\n",
        "    tokenLengths = combinedDF[\"tokenCode\"].apply(lambda x: len(x))\n",
        "    plt.scatter(tokenLengths, combinedDF[\"fileGrade\"])\n",
        "    plt.xlabel(\"Token Length\")\n",
        "    plt.ylabel(\"Grade\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    #graph the density of the grades vs length\n",
        "    count = []\n",
        "    countLow = []\n",
        "    countHigh = []\n",
        "    for i in range(1, combinedDF[\"tokenCode\"].apply(lambda x: len(x)).max() + 1):\n",
        "        count.append(combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) == i][\"fileGrade\"].mean())\n",
        "        countLow.append(combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) == i][\"fileGrade\"].quantile(.25))\n",
        "        countHigh.append(combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) == i][\"fileGrade\"].quantile(.75))\n",
        "\n",
        "                    \n",
        "\n",
        "    plt.scatter(range(1, combinedDF[\"tokenCode\"].apply(lambda x: len(x)).max() + 1), count)\n",
        "    #draw a line of best fit\n",
        "    z = np.polyfit(range(1, combinedDF[\"tokenCode\"].apply(lambda x: len(x)).max() + 1), count, 1)\n",
        "    p = np.poly1d(z)\n",
        "    plt.xlabel(\"Token Length\")\n",
        "    plt.ylabel(\"Grade\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jnja4-p705pU",
        "outputId": "b79f4a7d-57af-4836-e052-f2089eaec5b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                tokenCode  \\\n",
            "0       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "1       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "2       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "3       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "4       [22, 9, 22, 44, 422, 28, 612, 6, 742, 6, 639, ...   \n",
            "...                                                   ...   \n",
            "180559  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "180561  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "180564  [44, 422, 28, 1, 28, 266, 28, 79, 4, 24, 10, 3...   \n",
            "180565  [44, 422, 28, 1, 4, 24, 10, 3, 9, 3, 4, 25, 10...   \n",
            "180568  [44, 422, 28, 1, 28, 79, 4, 24, 10, 3, 9, 3, 4...   \n",
            "\n",
            "                                                     Path  fileGrade  \n",
            "0       3722273/examples/basics/linear_regression.py/1.py  59.000000  \n",
            "1       3722273/examples/basics/linear_regression.py/2.py  66.000000  \n",
            "2       3722273/examples/basics/linear_regression.py/3.py  67.000000  \n",
            "3       3722273/examples/basics/linear_regression.py/0.py  55.000000  \n",
            "4       3722273/examples/basics/linear_regression.py/4.py  71.000000  \n",
            "...                                                   ...        ...  \n",
            "180559                       3912822/pelicanconf.py/20.py  62.547170  \n",
            "180561                       3912822/pelicanconf.py/28.py  65.566038  \n",
            "180564                       3912822/pelicanconf.py/33.py  67.452830  \n",
            "180565                        3912822/pelicanconf.py/0.py  55.000000  \n",
            "180568                       3912822/pelicanconf.py/18.py  61.792453  \n",
            "\n",
            "[31747 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#Padding\n",
        "\n",
        "maxLen = 500\n",
        "minLen = 100\n",
        "#get rid of the ones that are too long\n",
        "combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) <= maxLen]\n",
        "\n",
        "#shorten the ones that are too long\n",
        "#combinedDF[\"tokenCode\"] = combinedDF[\"tokenCode\"].apply(lambda x: x[:maxLen])\n",
        "#combinedDF = combinedDF[combinedDF[\"tokenGroupCode\"].apply(lambda x: len(x)) <= maxLen]\n",
        " \n",
        "\n",
        "#get rid of the ones that are too short\n",
        "combinedDF = combinedDF[combinedDF[\"tokenCode\"].apply(lambda x: len(x)) > minLen]\n",
        "#combinedDF = combinedDF[combinedDF[\"tokenGroupCode\"].apply(lambda x: len(x)) > minLen]\n",
        "\n",
        "#Pad the sequences\n",
        "combinedDF[\"tokenCode\"] = pad_sequences(combinedDF[\"tokenCode\"], maxlen = maxLen, padding = \"post\", truncating = \"post\").tolist()\n",
        "#combinedDF[\"tokenGroupCode\"] = pad_sequences(combinedDF[\"tokenGroupCode\"], maxlen = maxLen, padding = \"post\", truncating = \"post\").tolist()\n",
        "\n",
        "print (combinedDF)\n",
        "\n",
        "#only use 5% of the dat\n",
        "#combinedDF = combinedDF.sample(frac = 0.001, random_state = 1)\n",
        "\n",
        "#48590 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2-_lF4pW05pU",
        "outputId": "0568f4dd-be12-4884-c67e-9e8592184df6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#create a chart of the grades\n",
        "graph = plt.hist(combinedDF['fileGrade'], bins=20, range=(0, 100))\n",
        "plt.xticks([0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100])\n",
        "plt.xlabel(\"Grade Range\")\n",
        "plt.ylabel(\"Number of Commits\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': [40872.640625, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906], 'accuracy': [0.01287553645670414, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[40872.640625, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906]\n",
            "[99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297]\n",
            "{'activation': 'elu', 'activation2': 'elu', 'activation3': 'tanh', 'activation4': 'softplus', 'batch_size': 128.0, 'dropout_rate': 0.3221856758071219, 'loss': 'mean_absolute_percentage_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efb21911360>\n",
            "{'loss': [3393.75146484375, 3393.522705078125, 3393.520263671875, 3393.521728515625, 3393.52197265625, 3393.522705078125, 3393.5224609375, 3393.52294921875], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[3393.75146484375, 3393.522705078125, 3393.520263671875, 3393.521728515625, 3393.52197265625, 3393.522705078125, 3393.5224609375, 3393.52294921875]\n",
            "[2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625, 2935.09765625]\n",
            "{'activation': 'elu', 'activation2': 'elu', 'activation3': 'softplus', 'activation4': 'sigmoid', 'batch_size': 128.0, 'dropout_rate': 0.28829215485568094, 'loss': 'mean_squared_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efb08590220>                              \n",
            "{'loss': [3393.5224609375, 3393.524658203125, 3393.52587890625, 3393.521240234375, 3393.521484375, 3393.522705078125, 3393.52294921875, 3393.524658203125], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[3393.5224609375, 3393.524658203125, 3393.52587890625, 3393.521240234375, 3393.521484375, 3393.522705078125, 3393.52294921875, 3393.524658203125]\n",
            "[2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875, 2935.096435546875]\n",
            "{'activation': 'softplus', 'activation2': 'elu', 'activation3': 'exponential', 'activation4': 'softmax', 'batch_size': 32.0, 'dropout_rate': 0.005204956918222814, 'loss': 'mean_squared_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efafb848fa0>                                \n",
            "{'loss': [3395.065673828125, 3393.52197265625, 3393.52197265625, 3393.521728515625, 3393.521728515625, 3393.521484375, 3393.52197265625, 3393.522705078125], 'accuracy': [0.00011812418961199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[3395.065673828125, 3393.52197265625, 3393.52197265625, 3393.521728515625, 3393.521728515625, 3393.521484375, 3393.52197265625, 3393.522705078125]\n",
            "[2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375]\n",
            "{'activation': 'softsign', 'activation2': 'selu', 'activation3': 'relu', 'activation4': 'tanh', 'batch_size': 320.0, 'dropout_rate': 0.03857355154256126, 'loss': 'mean_squared_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf6b41f90>                                \n",
            "{'loss': [733.56396484375, 225.7013397216797, 138.42135620117188, 104.7854995727539, 84.72850036621094, 75.79937744140625, 68.4410171508789, 63.14110565185547], 'accuracy': [0.00011812418961199, 0.006221207324415445, 0.009883057326078415, 0.01019805483520031, 0.010946175083518028, 0.010158680379390717, 0.01000118162482977, 0.01000118162482977], 'val_loss': [296.8609924316406, 340.6084289550781, 392.0177917480469, 335.1006774902344, 373.2398681640625, 410.2657775878906, 364.0542907714844, 366.47845458984375], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[733.56396484375, 225.7013397216797, 138.42135620117188, 104.7854995727539, 84.72850036621094, 75.79937744140625, 68.4410171508789, 63.14110565185547]\n",
            "[296.8609924316406, 340.6084289550781, 392.0177917480469, 335.1006774902344, 373.2398681640625, 410.2657775878906, 364.0542907714844, 366.47845458984375]\n",
            "{'activation': 'softmax', 'activation2': 'exponential', 'activation3': 'selu', 'activation4': 'softplus', 'batch_size': 288.0, 'dropout_rate': 0.10201705194924432, 'loss': 'mean_squared_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf88e0df0>                                \n",
            "{'loss': [355.41607666015625, 137.46969604492188, 88.9505386352539, 73.88609313964844, 62.96024703979492, 58.49747848510742, 56.093082427978516, 50.24639129638672], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [327.64166259765625, 351.6351623535156, 410.6303405761719, 395.50140380859375, 395.9068908691406, 390.051025390625, 374.8121337890625, 340.4890441894531], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[355.41607666015625, 137.46969604492188, 88.9505386352539, 73.88609313964844, 62.96024703979492, 58.49747848510742, 56.093082427978516, 50.24639129638672]\n",
            "[327.64166259765625, 351.6351623535156, 410.6303405761719, 395.50140380859375, 395.9068908691406, 390.051025390625, 374.8121337890625, 340.4890441894531]\n",
            "{'activation': 'tanh', 'activation2': 'sigmoid', 'activation3': 'softplus', 'activation4': 'softplus', 'batch_size': 192.0, 'dropout_rate': 0.23752665102190001, 'loss': 'mean_squared_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efb0b5d99c0>                               \n",
            "{'loss': [5074.49365234375, 48.42918014526367, 29.615861892700195, 15.839723587036133, 14.775038719177246, 14.258230209350586, 14.030807495117188, 13.735971450805664], 'accuracy': [0.010394928976893425, 0.007323699537664652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [50.33352279663086, 35.42852783203125, 15.165172576904297, 13.130219459533691, 18.92345428466797, 14.550379753112793, 13.923674583435059, 12.745840072631836], 'val_accuracy': [0.0006299212691374123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[5074.49365234375, 48.42918014526367, 29.615861892700195, 15.839723587036133, 14.775038719177246, 14.258230209350586, 14.030807495117188, 13.735971450805664]\n",
            "[50.33352279663086, 35.42852783203125, 15.165172576904297, 13.130219459533691, 18.92345428466797, 14.550379753112793, 13.923674583435059, 12.745840072631836]\n",
            "{'activation': 'softsign', 'activation2': 'softsign', 'activation3': 'softplus', 'activation4': 'exponential', 'batch_size': 224.0, 'dropout_rate': 0.2785460136680202, 'loss': 'mean_absolute_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efb0973a110>                               \n",
            "{'loss': [0.622484028339386, 0.4757199287414551, 0.4755912721157074, 0.4759245812892914, 0.4758029282093048, 0.47507113218307495, 0.45969289541244507, 0.4760562777519226], 'accuracy': [3.937472865800373e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00027562311151996255, 0.0], 'val_loss': [0.16775640845298767, 0.16730858385562897, 0.16784702241420746, 0.16743648052215576, 0.16727834939956665, 0.16783356666564941, 0.168087437748909, 0.1672949194908142], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[0.622484028339386, 0.4757199287414551, 0.4755912721157074, 0.4759245812892914, 0.4758029282093048, 0.47507113218307495, 0.45969289541244507, 0.4760562777519226]\n",
            "[0.16775640845298767, 0.16730858385562897, 0.16784702241420746, 0.16743648052215576, 0.16727834939956665, 0.16783356666564941, 0.168087437748909, 0.1672949194908142]\n",
            "{'activation': 'relu', 'activation2': 'softsign', 'activation3': 'softsign', 'activation4': 'relu', 'batch_size': 160.0, 'dropout_rate': 0.3059041659979243, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efad0533bb0>                                \n",
            "{'loss': [3393.521728515625, 3393.52197265625, 3393.5224609375, 3393.52197265625, 3393.521484375, 3393.521484375, 3393.52197265625, 3393.5224609375], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[3393.521728515625, 3393.52197265625, 3393.5224609375, 3393.52197265625, 3393.521484375, 3393.521484375, 3393.52197265625, 3393.5224609375]\n",
            "[2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375, 2935.097412109375]\n",
            "{'activation': 'selu', 'activation2': 'selu', 'activation3': 'softsign', 'activation4': 'softmax', 'batch_size': 224.0, 'dropout_rate': 0.0712375061606082, 'loss': 'mean_squared_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efad02660b0>                                \n",
            "{'loss': [12915007.0, 12915011.0, 12915008.0, 12915008.0, 12915010.0, 12915008.0, 12915008.0, 12915010.0], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[12915007.0, 12915011.0, 12915008.0, 12915008.0, 12915010.0, 12915008.0, 12915008.0, 12915010.0]\n",
            "[787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875, 787499.1875]\n",
            "{'activation': 'softmax', 'activation2': 'softplus', 'activation3': 'softsign', 'activation4': 'softmax', 'batch_size': 352.0, 'dropout_rate': 0.438115178851362, 'loss': 'mean_absolute_percentage_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf4eba680>                                \n",
            "{'loss': [61142.5078125, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906], 'accuracy': [0.012836162000894547, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[61142.5078125, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906, 98.70851135253906]\n",
            "[99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297, 99.92125701904297]\n",
            "{'activation': 'softsign', 'activation2': 'tanh', 'activation3': 'selu', 'activation4': 'sigmoid', 'batch_size': 192.0, 'dropout_rate': 0.24411120659045105, 'loss': 'mean_absolute_percentage_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efa9cb11c00>                                 \n",
            "{'loss': [12874761.0, 12915014.0, 12915012.0, 12915014.0, 12915019.0, 12915014.0, 12915016.0, 12915015.0], 'accuracy': [0.012757412157952785, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[12874761.0, 12915014.0, 12915012.0, 12915014.0, 12915019.0, 12915014.0, 12915016.0, 12915015.0]\n",
            "[787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625, 787503.5625]\n",
            "{'activation': 'softsign', 'activation2': 'softplus', 'activation3': 'exponential', 'activation4': 'elu', 'batch_size': 192.0, 'dropout_rate': 0.3768633789679149, 'loss': 'mean_absolute_percentage_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efa5861a050>                                 \n",
            "{'loss': [15.754806518554688, 15.754810333251953, 15.754812240600586, 15.754812240600586, 15.754815101623535, 15.754812240600586, 15.754807472229004, 15.754819869995117], 'accuracy': [0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[15.754806518554688, 15.754810333251953, 15.754812240600586, 15.754812240600586, 15.754815101623535, 15.754812240600586, 15.754807472229004, 15.754819869995117]\n",
            "[15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918]\n",
            "{'activation': 'exponential', 'activation2': 'exponential', 'activation3': 'softmax', 'activation4': 'selu', 'batch_size': 160.0, 'dropout_rate': 0.19256035619453143, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf4d2f8b0>                                 \n",
            "{'loss': [3397.20166015625, 3394.52783203125, 3394.320068359375, 3394.201904296875, 3394.1240234375, 3394.066650390625, 3394.02197265625, 3393.986572265625], 'accuracy': [0.00031499782926402986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [2936.201904296875, 2935.926513671875, 2935.7861328125, 2935.697998046875, 2935.635498046875, 2935.588623046875, 2935.551513671875, 2935.52099609375], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[3397.20166015625, 3394.52783203125, 3394.320068359375, 3394.201904296875, 3394.1240234375, 3394.066650390625, 3394.02197265625, 3393.986572265625]\n",
            "[2936.201904296875, 2935.926513671875, 2935.7861328125, 2935.697998046875, 2935.635498046875, 2935.588623046875, 2935.551513671875, 2935.52099609375]\n",
            "{'activation': 'selu', 'activation2': 'elu', 'activation3': 'softsign', 'activation4': 'softsign', 'batch_size': 320.0, 'dropout_rate': 0.4515831013014653, 'loss': 'mean_squared_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf6bb24d0>                                 \n",
            "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan], 'accuracy': [0.012678663246333599, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[nan, nan, nan, nan, nan, nan, nan, nan]                                               \n",
            "[nan, nan, nan, nan, nan, nan, nan, nan]                                               \n",
            "{'activation': 'exponential', 'activation2': 'exponential', 'activation3': 'sigmoid', 'activation4': 'exponential', 'batch_size': 320.0, 'dropout_rate': 0.057065748549160966, 'loss': 'mean_squared_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efa883afe20>                                 \n",
            "{'loss': [77.93937683105469, 55.575408935546875, 55.372135162353516, 55.169342041015625, 54.966758728027344, 54.76444625854492, 54.56238555908203, 54.36063003540039], 'accuracy': [0.012678663246333599, 0.012914910912513733, 0.005551836919039488, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [52.65605163574219, 52.44712448120117, 52.23851776123047, 52.03016662597656, 51.8221549987793, 51.61406326293945, 51.406131744384766, 51.1984748840332], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[77.93937683105469, 55.575408935546875, 55.372135162353516, 55.169342041015625, 54.966758728027344, 54.76444625854492, 54.56238555908203, 54.36063003540039]\n",
            "[52.65605163574219, 52.44712448120117, 52.23851776123047, 52.03016662597656, 51.8221549987793, 51.61406326293945, 51.406131744384766, 51.1984748840332]\n",
            "{'activation': 'sigmoid', 'activation2': 'exponential', 'activation3': 'exponential', 'activation4': 'selu', 'batch_size': 128.0, 'dropout_rate': 0.34105806404222594, 'loss': 'mean_absolute_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efa883271f0>                                 \n",
            "{'loss': [54.90345764160156, 54.899085998535156, 54.89907455444336, 54.899085998535156, 54.89908218383789, 54.89908218383789, 54.89910888671875, 54.899078369140625], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[54.90345764160156, 54.899085998535156, 54.89907455444336, 54.899085998535156, 54.89908218383789, 54.89908218383789, 54.89910888671875, 54.899078369140625]\n",
            "[51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281, 51.85737609863281]\n",
            "{'activation': 'selu', 'activation2': 'elu', 'activation3': 'softsign', 'activation4': 'sigmoid', 'batch_size': 160.0, 'dropout_rate': 0.031215283078256884, 'loss': 'mean_absolute_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efafd998cd0>                                 \n",
            "{'loss': [14.473299980163574, 14.372968673706055, 14.354009628295898, 14.352510452270508, 14.371007919311523, 14.34269905090332, 14.347126007080078, 14.393671989440918], 'accuracy': [3.937472865800373e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [13.075715065002441, 13.331436157226562, 12.68996524810791, 13.037053108215332, 13.168907165527344, 12.808423042297363, 12.62134838104248, 12.985016822814941], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[14.473299980163574, 14.372968673706055, 14.354009628295898, 14.352510452270508, 14.371007919311523, 14.34269905090332, 14.347126007080078, 14.393671989440918]\n",
            "[13.075715065002441, 13.331436157226562, 12.68996524810791, 13.037053108215332, 13.168907165527344, 12.808423042297363, 12.62134838104248, 12.985016822814941]\n",
            "{'activation': 'softsign', 'activation2': 'softplus', 'activation3': 'tanh', 'activation4': 'selu', 'batch_size': 64.0, 'dropout_rate': 0.32379142557794677, 'loss': 'mean_absolute_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efb21ac81c0>                                 \n",
            "{'loss': [0.5599841475486755, 0.20432737469673157, 0.1791675090789795, 0.15569208562374115, 0.1324077695608139, 0.11150190979242325, 0.10340559482574463, 0.08775864541530609], 'accuracy': [0.00043312201160006225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005512462230399251, 0.0012993661221116781], 'val_loss': [0.24981218576431274, 0.23509615659713745, 0.24848763644695282, 0.27289676666259766, 0.25316786766052246, 0.24715584516525269, 0.24772268533706665, 0.34393924474716187], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[0.5599841475486755, 0.20432737469673157, 0.1791675090789795, 0.15569208562374115, 0.1324077695608139, 0.11150190979242325, 0.10340559482574463, 0.08775864541530609]\n",
            "[0.24981218576431274, 0.23509615659713745, 0.24848763644695282, 0.27289676666259766, 0.25316786766052246, 0.24715584516525269, 0.24772268533706665, 0.34393924474716187]\n",
            "{'activation': 'softmax', 'activation2': 'softplus', 'activation3': 'relu', 'activation4': 'selu', 'batch_size': 256.0, 'dropout_rate': 0.42479188545312285, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efb225365f0>                                 \n",
            "{'loss': [0.709848940372467, 0.4772418737411499, 0.47566652297973633, 0.4386151134967804, 0.287842333316803, 0.20185664296150208, 0.17944736778736115, 0.16926294565200806], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.00047249675844796, 0.0005118714761920273, 0.0, 0.00039374729385599494], 'val_loss': [0.17964401841163635, 0.16747286915779114, 0.1680334061384201, 0.2781338095664978, 0.37797340750694275, 0.31712213158607483, 0.2693310081958771, 0.28981292247772217], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[0.709848940372467, 0.4772418737411499, 0.47566652297973633, 0.4386151134967804, 0.287842333316803, 0.20185664296150208, 0.17944736778736115, 0.16926294565200806]\n",
            "[0.17964401841163635, 0.16747286915779114, 0.1680334061384201, 0.2781338095664978, 0.37797340750694275, 0.31712213158607483, 0.2693310081958771, 0.28981292247772217]\n",
            "{'activation': 'softplus', 'activation2': 'selu', 'activation3': 'softplus', 'activation4': 'relu', 'batch_size': 320.0, 'dropout_rate': 0.3344654340753082, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efad80c6ce0>                                  \n",
            "{'loss': [306.3680419921875, 136.50967407226562, 95.0545654296875, 76.97002410888672, 68.50043487548828, 59.051029205322266, 55.827613830566406, 51.508338928222656], 'accuracy': [0.004646217916160822, 0.006733078509569168, 0.007008702028542757, 0.007323699537664652, 0.008189943619072437, 0.008071819320321083, 0.008268693462014198, 0.008308067917823792], 'val_loss': [353.77777099609375, 455.76251220703125, 436.9079284667969, 447.0681457519531, 364.84716796875, 399.0730285644531, 348.29913330078125, 341.0273132324219], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[306.3680419921875, 136.50967407226562, 95.0545654296875, 76.97002410888672, 68.50043487548828, 59.051029205322266, 55.827613830566406, 51.508338928222656]\n",
            "[353.77777099609375, 455.76251220703125, 436.9079284667969, 447.0681457519531, 364.84716796875, 399.0730285644531, 348.29913330078125, 341.0273132324219]\n",
            "{'activation': 'elu', 'activation2': 'elu', 'activation3': 'selu', 'activation4': 'selu', 'batch_size': 192.0, 'dropout_rate': 0.1027454756105442, 'loss': 'mean_squared_error', 'optimizer': 'Adam'}\n",
            "<keras.src.callbacks.History object at 0x7efb22d86590>                                  \n",
            "{'loss': [0.7796074151992798, 0.5043948888778687, 0.48101314902305603, 0.4761967062950134, 0.47541940212249756, 0.47530505061149597, 0.47529852390289307, 0.47528931498527527], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.23051130771636963, 0.1826411932706833, 0.17093241214752197, 0.16826589405536652, 0.16771242022514343, 0.16755753755569458, 0.167501762509346, 0.16748440265655518], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[0.7796074151992798, 0.5043948888778687, 0.48101314902305603, 0.4761967062950134, 0.47541940212249756, 0.47530505061149597, 0.47529852390289307, 0.47528931498527527]\n",
            "[0.23051130771636963, 0.1826411932706833, 0.17093241214752197, 0.16826589405536652, 0.16771242022514343, 0.16755753755569458, 0.167501762509346, 0.16748440265655518]\n",
            "{'activation': 'softplus', 'activation2': 'relu', 'activation3': 'sigmoid', 'activation4': 'relu', 'batch_size': 256.0, 'dropout_rate': 0.3937779911104679, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efaaef3a5f0>                                  \n",
            "{'loss': [6.9686994552612305, 1.519201636314392, 0.7894721627235413, 0.5816501379013062, 0.5115953087806702, 0.4871176481246948, 0.4788255989551544, 0.4762525260448456], 'accuracy': [0.0018112375400960445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [2.1147618293762207, 0.7050678133964539, 0.35121360421180725, 0.23323607444763184, 0.19141000509262085, 0.17602260410785675, 0.17049212753772736, 0.16855940222740173], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[6.9686994552612305, 1.519201636314392, 0.7894721627235413, 0.5816501379013062, 0.5115953087806702, 0.4871176481246948, 0.4788255989551544, 0.4762525260448456]\n",
            "[2.1147618293762207, 0.7050678133964539, 0.35121360421180725, 0.23323607444763184, 0.19141000509262085, 0.17602260410785675, 0.17049212753772736, 0.16855940222740173]\n",
            "{'activation': 'softplus', 'activation2': 'softmax', 'activation3': 'relu', 'activation4': 'relu', 'batch_size': 352.0, 'dropout_rate': 0.49443050030996905, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efb21ba2080>                                  \n",
            "{'loss': [1.0407531261444092, 0.25785934925079346, 0.2070828676223755, 0.1638399213552475, 0.14338421821594238, 0.12274041026830673, 0.10839676111936569, 0.103891521692276], 'accuracy': [0.00035437257611192763, 0.0012993661221116781, 0.004764342214912176, 0.003701224457472563, 0.0051187146455049515, 0.004252470564097166, 0.005276213865727186, 0.0035831003915518522], 'val_loss': [0.2471647709608078, 0.21848472952842712, 0.3216151297092438, 0.3053191006183624, 0.3248180150985718, 0.31488004326820374, 0.29383957386016846, 0.2867927849292755], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[1.0407531261444092, 0.25785934925079346, 0.2070828676223755, 0.1638399213552475, 0.14338421821594238, 0.12274041026830673, 0.10839676111936569, 0.103891521692276]\n",
            "[0.2471647709608078, 0.21848472952842712, 0.3216151297092438, 0.3053191006183624, 0.3248180150985718, 0.31488004326820374, 0.29383957386016846, 0.2867927849292755]\n",
            "{'activation': 'softmax', 'activation2': 'selu', 'activation3': 'elu', 'activation4': 'relu', 'batch_size': 288.0, 'dropout_rate': 0.4789925978690781, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efa5864be20>                                  \n",
            "{'loss': [56.384056091308594, 15.754812240600586, 15.754810333251953, 15.754812240600586, 15.75481128692627, 15.754816055297852, 15.754812240600586, 15.754812240600586], 'accuracy': [0.012599913403391838, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[56.384056091308594, 15.754812240600586, 15.754810333251953, 15.754812240600586, 15.75481128692627, 15.754816055297852, 15.754812240600586, 15.754812240600586]\n",
            "[15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918]\n",
            "{'activation': 'softmax', 'activation2': 'softplus', 'activation3': 'elu', 'activation4': 'exponential', 'batch_size': 256.0, 'dropout_rate': 0.4980643953299937, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efafd99b490>                                  \n",
            "{'loss': [10.95106315612793, 10.816370964050293, 10.81637191772461, 10.816370010375977, 10.816370010375977, 10.816370964050293, 10.816370964050293, 10.816370010375977], 'accuracy': [0.0006693704053759575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[10.95106315612793, 10.816370964050293, 10.81637191772461, 10.816370010375977, 10.816370010375977, 10.816370964050293, 10.816370964050293, 10.816370010375977]\n",
            "[10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508, 10.605684280395508]\n",
            "{'activation': 'softmax', 'activation2': 'relu', 'activation3': 'elu', 'activation4': 'tanh', 'batch_size': 288.0, 'dropout_rate': 0.4341227806644181, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf9809ab0>                                   \n",
            "{'loss': [0.6168160438537598, 0.2073405385017395, 0.1453161984682083, 0.11483500152826309, 0.09740706533193588, 0.08571968972682953, 0.07798098027706146, 0.07316095381975174], 'accuracy': [3.937472865800373e-05, 7.874945731600747e-05, 0.0, 0.0, 0.0, 0.0012599913170561194, 0.0027956056874245405, 0.0029924793634563684], 'val_loss': [0.2160882204771042, 0.26985400915145874, 0.23613515496253967, 0.2415848970413208, 0.2606707811355591, 0.24746064841747284, 0.3055999279022217, 0.27451440691947937], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[0.6168160438537598, 0.2073405385017395, 0.1453161984682083, 0.11483500152826309, 0.09740706533193588, 0.08571968972682953, 0.07798098027706146, 0.07316095381975174]\n",
            "[0.2160882204771042, 0.26985400915145874, 0.23613515496253967, 0.2415848970413208, 0.2606707811355591, 0.24746064841747284, 0.3055999279022217, 0.27451440691947937]\n",
            "{'activation': 'softmax', 'activation2': 'sigmoid', 'activation3': 'relu', 'activation4': 'elu', 'batch_size': 256.0, 'dropout_rate': 0.4804562683998622, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efad01cb160>                                   \n",
            "{'loss': [0.5490217804908752, 0.19271138310432434, 0.13597369194030762, 0.11060700565576553, 0.09367667138576508, 0.08364218473434448, 0.07641267776489258, 0.07080847024917603], 'accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008662440232001245, 0.002086860593408346], 'val_loss': [0.22067931294441223, 0.28343743085861206, 0.20506447553634644, 0.26839694380760193, 0.26783913373947144, 0.23767635226249695, 0.2741182744503021, 0.34645354747772217], 'val_accuracy': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
            "[0.5490217804908752, 0.19271138310432434, 0.13597369194030762, 0.11060700565576553, 0.09367667138576508, 0.08364218473434448, 0.07641267776489258, 0.07080847024917603]\n",
            "[0.22067931294441223, 0.28343743085861206, 0.20506447553634644, 0.26839694380760193, 0.26783913373947144, 0.23767635226249695, 0.2741182744503021, 0.34645354747772217]\n",
            "{'activation': 'softmax', 'activation2': 'sigmoid', 'activation3': 'relu', 'activation4': 'elu', 'batch_size': 256.0, 'dropout_rate': 0.3973481388320767, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf4a50b20>                                   \n",
            "{'loss': [15.754813194274902, 15.754812240600586, 15.75480842590332, 15.754812240600586, 15.754810333251953, 15.754810333251953, 15.754810333251953, 15.754812240600586], 'accuracy': [0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[15.754813194274902, 15.754812240600586, 15.75480842590332, 15.754812240600586, 15.754810333251953, 15.754810333251953, 15.754810333251953, 15.754812240600586]\n",
            "[15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602, 15.565057754516602]\n",
            "{'activation': 'relu', 'activation2': 'sigmoid', 'activation3': 'relu', 'activation4': 'elu', 'batch_size': 224.0, 'dropout_rate': 0.3807327868515408, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efaf4ad5870>                                 \n",
            "{'loss': [15.754807472229004, 15.754813194274902, 15.754810333251953, 15.754810333251953, 15.754806518554688, 15.754810333251953, 15.75480842590332, 15.754810333251953], 'accuracy': [0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733, 0.012914910912513733], 'val_loss': [15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918], 'val_accuracy': [0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502, 0.0007874015718698502]}\n",
            "[15.754807472229004, 15.754813194274902, 15.754810333251953, 15.754810333251953, 15.754806518554688, 15.754810333251953, 15.75480842590332, 15.754810333251953]\n",
            "[15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918, 15.565058708190918]\n",
            "{'activation': 'exponential', 'activation2': 'sigmoid', 'activation3': 'relu', 'activation4': 'elu', 'batch_size': 256.0, 'dropout_rate': 0.4632122406542385, 'loss': 'mean_squared_logarithmic_error', 'optimizer': 'Nadam'}\n",
            "<keras.src.callbacks.History object at 0x7efaaef3b280>                                 \n",
            "100%|| 30/30 [11:46:55<00:00, 1413.84s/trial, best loss: 0.07080847024917603]\n",
            "{'activation': 3, 'activation2': 2, 'activation3': 0, 'activation4': 7, 'batch_size': 256.0, 'dropout_rate': 0.3973481388320767, 'loss': 3, 'optimizer': 1}\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'hyperopt.hp' has no attribute 'space_eval'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(best)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Get the values of the optimal parameters\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace_eval\u001b[49m(space, best)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_params)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'hyperopt.hp' has no attribute 'space_eval'"
          ]
        }
      ],
      "source": [
        "from hyperopt import hp, fmin, tpe\n",
        "from hyperopt import STATUS_OK\n",
        "from tokenize import TokenInfo\n",
        "\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from keras.optimizers import Nadam, Adam\n",
        "from keras.losses import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, mean_squared_logarithmic_error, squared_hinge, hinge, categorical_hinge, logcosh,  categorical_crossentropy, sparse_categorical_crossentropy, binary_crossentropy, kullback_leibler_divergence, poisson\n",
        "\n",
        "# Define the search space for the hyperparameters\n",
        "space = {\n",
        "    'loss' : hp.choice('loss', ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error']),\n",
        "    'batch_size': hp.quniform('batch_size', 32, 360, 32),\n",
        "    'optimizer': hp.choice('optimizer', ['Adam', 'Nadam']),\n",
        "    'dropout_rate': hp.uniform('dropout_rate', 0, 0.5),\n",
        "    'activation': hp.choice('activation', ['relu', 'tanh', 'sigmoid', 'softmax', 'softplus', 'softsign', 'selu', 'elu', 'exponential']),\n",
        "    'activation2' : hp.choice('activation2', ['relu', 'tanh', 'sigmoid', 'softmax', 'softplus', 'softsign', 'selu', 'elu', 'exponential']),\n",
        "    'activation3' : hp.choice('activation3', ['relu', 'tanh', 'sigmoid', 'softmax', 'softplus', 'softsign', 'selu', 'elu', 'exponential']),\n",
        "    'activation4' : hp.choice('activation4', ['relu', 'tanh', 'sigmoid', 'softmax', 'softplus', 'softsign', 'selu', 'elu', 'exponential']),\n",
        "    }\n",
        "\n",
        "# Define the objective function\n",
        "def objective(params):\n",
        "    inputTokens = layers.Input(shape=(maxLen,), dtype='int32')\n",
        "    #Embedding\n",
        "    embedding = layers.Embedding(tokenizer.num_words, 2048, input_length=maxLen)(inputTokens)\n",
        "\n",
        "    #Convolutional\n",
        "    convolutional = layers.Conv1D(2048, 3, activation=params['activation'])(embedding)\n",
        "    convolutional = layers.GlobalMaxPooling1D()(convolutional)\n",
        "    convolutional = layers.Reshape((1, 2048))(convolutional)\n",
        "\n",
        "    #LSTM\n",
        "    lstm = layers.Bidirectional(LSTM(1024, return_sequences=True))(convolutional)\n",
        "    lstm = Dropout(params['dropout_rate'])(lstm)\n",
        "    lstm = layers.Bidirectional(LSTM(512))(lstm)\n",
        "\n",
        "    #Dense\n",
        "    dense = layers.Flatten()(lstm)\n",
        "    dense = layers.Dense(4096, activation=params['activation2'])(dense)\n",
        "    dense = layers.Dense(2048, activation=params['activation3'])(dense)\n",
        "    dense = layers.Dense(1, activation=params['activation4'])(dense)\n",
        "\n",
        "    #Output\n",
        "    output = dense\n",
        "    model = Model(inputs=inputTokens, outputs=output)\n",
        "\n",
        "    #Compile\n",
        "    if params['optimizer'] == 'Adam':\n",
        "        optimizer = Adam()\n",
        "    else:\n",
        "        optimizer = Nadam()\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=params['loss'], metrics=['accuracy'])\n",
        "\n",
        "    #Train\n",
        "    history = model.fit(np.array(combinedDF[\"tokenCode\"].tolist()), np.array(combinedDF[\"fileGrade\"].tolist()), batch_size=int(params['batch_size']), epochs=8, validation_split=0.2, verbose=0)\n",
        "\n",
        "    print (history.history)\n",
        "    print (history.history['loss'])\n",
        "    print (history.history['val_loss'])\n",
        "    # Return the loss\n",
        "    MSE = abs(history.history['loss'][-1])\n",
        "    \n",
        "    print(params, history)\n",
        "    return abs(MSE)\n",
        "\n",
        "# Run the hyperparameter search using the TPE algorithm\n",
        "best = fmin(objective, space, algo=tpe.suggest, max_evals=30)\n",
        "print(best)\n",
        "\n",
        "# Get the values of the optimal parameters\n",
        "best_params = hp.space_eval(space, best)\n",
        "print(best_params)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
